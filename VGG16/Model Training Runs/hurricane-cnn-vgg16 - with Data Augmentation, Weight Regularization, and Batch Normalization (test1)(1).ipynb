{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"execution":{"iopub.status.busy":"2021-08-13T17:24:20.382233Z","iopub.execute_input":"2021-08-13T17:24:20.382698Z","iopub.status.idle":"2021-08-13T17:24:20.387768Z","shell.execute_reply.started":"2021-08-13T17:24:20.382668Z","shell.execute_reply":"2021-08-13T17:24:20.386839Z"}}},{"cell_type":"code","source":"import numpy as np\nimport glob\nfrom PIL import Image\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import optimizers\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\nimport pandas as pd\nimport seaborn as sn\nsn.set(font_scale=1.4) # for label size\nimport multiprocessing as mp\nimport csv","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:02:00.059613Z","iopub.execute_input":"2021-09-11T22:02:00.060025Z","iopub.status.idle":"2021-09-11T22:02:05.291677Z","shell.execute_reply.started":"2021-09-11T22:02:00.059914Z","shell.execute_reply":"2021-09-11T22:02:05.290836Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load DataSet\n\n0 means unlikely to have flood damage, 1 means likely to have flood damage\n\n[0,1] --> damage\n\n[1,0] --> no damage","metadata":{}},{"cell_type":"markdown","source":"## Load Training Set","metadata":{}},{"cell_type":"code","source":"images = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/train_another/damage/*.jpeg')\ndmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  dmg_img.append(im_arr)\ndmg_img = np.array(dmg_img)\n\nimages = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/train_another/no_damage/*.jpeg')\nno_dmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  no_dmg_img.append(im_arr)\nno_dmg_img = np.array(no_dmg_img)\n\nX_train = np.concatenate((dmg_img, no_dmg_img))\ndmg_img_y = np.array(dmg_img.shape[0] * [[0,1]])\nno_dmg_img_y = np.array(no_dmg_img.shape[0] * [[1,0]])\ny_train = np.concatenate((dmg_img_y, no_dmg_img_y))\n\n# shuffle arrays so that the array is a mix of damage and no_damage in a random order\nshuffler = np.random.permutation(X_train.shape[0])\nX_train = X_train[shuffler]\ny_train = y_train[shuffler]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:02:10.984891Z","iopub.execute_input":"2021-09-11T22:02:10.985245Z","iopub.status.idle":"2021-09-11T22:03:14.588286Z","shell.execute_reply.started":"2021-09-11T22:02:10.985213Z","shell.execute_reply":"2021-09-11T22:03:14.587346Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load Validation Set","metadata":{}},{"cell_type":"code","source":"images = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/validation_another/damage/*.jpeg')\ndmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  dmg_img.append(im_arr)\ndmg_img = np.array(dmg_img)\n\nimages = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/validation_another/no_damage/*.jpeg')\nno_dmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  no_dmg_img.append(im_arr)\nno_dmg_img = np.array(no_dmg_img)\n\nX_val = np.concatenate((dmg_img, no_dmg_img))\ndmg_img_y = np.array(dmg_img.shape[0] * [[0,1]])\nno_dmg_img_y = np.array(no_dmg_img.shape[0] * [[1,0]])\ny_val = np.concatenate((dmg_img_y, no_dmg_img_y))\n\n# shuffle arrays so that the array is a mix of damage and no_damage in a random order\nshuffler = np.random.permutation(X_val.shape[0])\nX_val = X_val[shuffler]\ny_val = y_val[shuffler]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:14.589653Z","iopub.execute_input":"2021-09-11T22:03:14.589979Z","iopub.status.idle":"2021-09-11T22:03:25.575116Z","shell.execute_reply.started":"2021-09-11T22:03:14.589943Z","shell.execute_reply":"2021-09-11T22:03:25.574250Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load Test Set","metadata":{}},{"cell_type":"code","source":"images = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/test/damage/*.jpeg')\ndmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  dmg_img.append(im_arr)\ndmg_img = np.array(dmg_img)\n\nimages = glob.glob('/kaggle/input/satellite-images-of-hurricane-damage/test/no_damage/*.jpeg')\nno_dmg_img = []\nfor i in images:\n  im = Image.open(i)\n  im_arr = np.array(im)\n  no_dmg_img.append(im_arr)\nno_dmg_img = np.array(no_dmg_img)\n\nX_test = np.concatenate((dmg_img, no_dmg_img))\ndmg_img_y = np.array(dmg_img.shape[0] * [[0,1]])\nno_dmg_img_y = np.array(no_dmg_img.shape[0] * [[1,0]])\ny_test = np.concatenate((dmg_img_y, no_dmg_img_y))\n\n# shuffle arrays so that the array is a mix of damage and no_damage in a random order\nshuffler = np.random.permutation(X_val.shape[0])\nX_test = X_test[shuffler]\ny_test = y_test[shuffler]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:25.576905Z","iopub.execute_input":"2021-09-11T22:03:25.577258Z","iopub.status.idle":"2021-09-11T22:03:36.407404Z","shell.execute_reply.started":"2021-09-11T22:03:25.577222Z","shell.execute_reply":"2021-09-11T22:03:36.406528Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Process DataSet","metadata":{}},{"cell_type":"code","source":"# pre-process data \ndef scale_pixels(train, val, test):\n\t# convert from integers to floats and normalize between 0-1\n  train_norm = train.astype('float32') / 255.0\n  val_norm = val.astype('float32') / 255.0\n  test_norm = test.astype('float32') / 255.0\n\t# return normalized images\n  return train_norm, val_norm, test_norm\n\nX_train, X_val, X_test = scale_pixels(X_train, X_val, X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:36.408931Z","iopub.execute_input":"2021-09-11T22:03:36.409282Z","iopub.status.idle":"2021-09-11T22:03:37.330911Z","shell.execute_reply.started":"2021-09-11T22:03:36.409244Z","shell.execute_reply":"2021-09-11T22:03:37.330059Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Plot Diagnostics","metadata":{}},{"cell_type":"code","source":"# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n  # blue = training data; orange = validation data\n\t# plot validation loss\n\tplt.subplot(211)\n\tplt.title('Cross Entropy Loss')\n\tplt.plot(history.history['loss'], color='blue', label='train')\n\tplt.plot(history.history['val_loss'], color='orange', label='validation')\n\t# plot accuracy\n\tplt.subplot(212)\n\tplt.title('Classification Accuracy')\n\tplt.plot(history.history['accuracy'], color='blue', label='train')\n\tplt.plot(history.history['val_accuracy'], color='orange', label='validation')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.332195Z","iopub.execute_input":"2021-09-11T22:03:37.332719Z","iopub.status.idle":"2021-09-11T22:03:37.339050Z","shell.execute_reply.started":"2021-09-11T22:03:37.332678Z","shell.execute_reply":"2021-09-11T22:03:37.338077Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Create CNN Model","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 3)))\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T00:02:17.460442Z","iopub.status.idle":"2021-09-11T00:02:17.461249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model with Batch Normalization","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model_batch_normalization(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 3)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T00:03:30.882895Z","iopub.execute_input":"2021-09-11T00:03:30.883242Z","iopub.status.idle":"2021-09-11T00:03:30.902605Z","shell.execute_reply.started":"2021-09-11T00:03:30.883212Z","shell.execute_reply":"2021-09-11T00:03:30.901578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model with Dropout Regularization","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model_dropout_regularization(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 3)))\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.Dropout(0.5))\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.Dropout(0.5))\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:54:18.496443Z","iopub.execute_input":"2021-09-11T18:54:18.496807Z","iopub.status.idle":"2021-09-11T18:54:18.51687Z","shell.execute_reply.started":"2021-09-11T18:54:18.496768Z","shell.execute_reply":"2021-09-11T18:54:18.515579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN Model with Dropout Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model_dropout_regularization_batch_normalization(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 3)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dropout(0.5))\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dropout(0.5))\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:54:18.518279Z","iopub.execute_input":"2021-09-11T18:54:18.518707Z","iopub.status.idle":"2021-09-11T18:54:18.539715Z","shell.execute_reply.started":"2021-09-11T18:54:18.518666Z","shell.execute_reply":"2021-09-11T18:54:18.539002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model with Weight Regularization","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model_weight_regularization(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001), input_shape=(128, 128, 3)))\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.340398Z","iopub.execute_input":"2021-09-11T22:03:37.340815Z","iopub.status.idle":"2021-09-11T22:03:37.362818Z","shell.execute_reply.started":"2021-09-11T22:03:37.340776Z","shell.execute_reply":"2021-09-11T22:03:37.362066Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### CNN Model with Weight Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"# define cnn model\ndef define_model_weight_regularization_batch_normalization(learning_rate):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001), input_shape=(128, 128, 3)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization()) \n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.364167Z","iopub.execute_input":"2021-09-11T22:03:37.364529Z","iopub.status.idle":"2021-09-11T22:03:37.386673Z","shell.execute_reply.started":"2021-09-11T22:03:37.364493Z","shell.execute_reply":"2021-09-11T22:03:37.385712Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# define cnn model\ndef define_model_weight_regularization_batch_normalization2(learning_rate, regularization_lambda):\n  model = keras.Sequential()\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda), input_shape=(128, 128, 3)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization()) \n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(4096, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(regularization_lambda)))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(2, activation='softmax'))  # compile model\n  opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.389616Z","iopub.execute_input":"2021-09-11T22:03:37.389981Z","iopub.status.idle":"2021-09-11T22:03:37.412599Z","shell.execute_reply.started":"2021-09-11T22:03:37.389947Z","shell.execute_reply":"2021-09-11T22:03:37.411784Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train Data\nHyperparameters are inputted into the function","metadata":{}},{"cell_type":"code","source":"def train(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-05T19:33:40.070898Z","iopub.execute_input":"2021-09-05T19:33:40.071186Z","iopub.status.idle":"2021-09-05T19:33:40.0826Z","shell.execute_reply.started":"2021-09-05T19:33:40.071159Z","shell.execute_reply":"2021-09-05T19:33:40.081745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test, accuracy = train(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 75)\nprint(accuracy)\ny_pred = model_test.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-15T18:17:36.414439Z","iopub.execute_input":"2021-08-15T18:17:36.414855Z","iopub.status.idle":"2021-08-15T22:54:08.378534Z","shell.execute_reply.started":"2021-08-15T18:17:36.414813Z","shell.execute_reply":"2021-08-15T22:54:08.376979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_batch_normalization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-05T19:33:40.111352Z","iopub.execute_input":"2021-09-05T19:33:40.111718Z","iopub.status.idle":"2021-09-05T19:33:40.118665Z","shell.execute_reply.started":"2021-09-05T19:33:40.111684Z","shell.execute_reply":"2021-09-05T19:33:40.117698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 75)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-05T16:06:26.618774Z","iopub.execute_input":"2021-09-05T16:06:26.619116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune Hyperparameters - learning rate","metadata":{}},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.0005, 75)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T20:53:38.318317Z","iopub.execute_input":"2021-08-29T20:53:38.318719Z","iopub.status.idle":"2021-08-29T23:56:44.027575Z","shell.execute_reply.started":"2021-08-29T20:53:38.318687Z","shell.execute_reply":"2021-08-29T23:56:44.026289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.005, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T00:24:07.687028Z","iopub.execute_input":"2021-08-30T00:24:07.68742Z","iopub.status.idle":"2021-08-30T03:38:17.481347Z","shell.execute_reply.started":"2021-08-30T00:24:07.687387Z","shell.execute_reply":"2021-08-30T03:38:17.479736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.01, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T03:48:43.065445Z","iopub.execute_input":"2021-08-30T03:48:43.066027Z","iopub.status.idle":"2021-08-30T06:33:29.824886Z","shell.execute_reply.started":"2021-08-30T03:48:43.065988Z","shell.execute_reply":"2021-08-30T06:33:29.823648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.1, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T12:55:41.349719Z","iopub.execute_input":"2021-08-30T12:55:41.350066Z","iopub.status.idle":"2021-08-30T16:45:51.955905Z","shell.execute_reply.started":"2021-08-30T12:55:41.350033Z","shell.execute_reply":"2021-08-30T16:45:51.954795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune Hyperparameters - batch size","metadata":{}},{"cell_type":"code","source":"def train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, batch_size, epochs):\n  # define model\n  model = define_model_batch_normalization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:26:57.050948Z","iopub.execute_input":"2021-08-30T23:26:57.051331Z","iopub.status.idle":"2021-08-30T23:26:57.067032Z","shell.execute_reply.started":"2021-08-30T23:26:57.051302Z","shell.execute_reply":"2021-08-30T23:26:57.065841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.005, 128, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:03:59.772379Z","iopub.execute_input":"2021-08-30T18:03:59.772742Z","iopub.status.idle":"2021-08-30T21:44:02.847318Z","shell.execute_reply.started":"2021-08-30T18:03:59.772712Z","shell.execute_reply":"2021-08-30T21:44:02.846381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.005, 32, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:26:57.068726Z","iopub.execute_input":"2021-08-30T23:26:57.069178Z","iopub.status.idle":"2021-08-31T02:20:40.900326Z","shell.execute_reply.started":"2021-08-30T23:26:57.069076Z","shell.execute_reply":"2021-08-31T02:20:40.898832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_batch_normalization, accuracy = train_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.005, 256, 40)\nprint(accuracy)\ny_pred = model_test_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T02:34:33.811804Z","iopub.execute_input":"2021-08-31T02:34:33.812233Z","iopub.status.idle":"2021-08-31T03:58:02.540322Z","shell.execute_reply.started":"2021-08-31T02:34:33.812198Z","shell.execute_reply":"2021-08-31T03:58:02.539196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Data Augmentation","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=8, verbose=1)\n\t# fit model\n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:56:42.240023Z","iopub.execute_input":"2021-08-28T04:56:42.240465Z","iopub.status.idle":"2021-08-28T04:56:42.253791Z","shell.execute_reply.started":"2021-08-28T04:56:42.240432Z","shell.execute_reply":"2021-08-28T04:56:42.252813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data, accuracy = train_data_augmentation(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 50)\nprint(accuracy)\ny_pred = model_test_data.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:56:50.64279Z","iopub.execute_input":"2021-08-28T04:56:50.643125Z","iopub.status.idle":"2021-08-28T12:37:13.502832Z","shell.execute_reply.started":"2021-08-28T04:56:50.64309Z","shell.execute_reply":"2021-08-28T12:37:13.502064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Data with Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_batch_normalization(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n\t# fit model  \n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T00:03:37.61526Z","iopub.execute_input":"2021-09-11T00:03:37.61561Z","iopub.status.idle":"2021-09-11T00:03:37.623616Z","shell.execute_reply.started":"2021-09-11T00:03:37.615575Z","shell.execute_reply":"2021-09-11T00:03:37.622576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_augmentation_batch_normalization, accuracy = train_data_augmentation_batch_normalization(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_augmentation_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T00:03:39.167356Z","iopub.execute_input":"2021-09-11T00:03:39.167683Z","iopub.status.idle":"2021-09-11T00:15:49.500466Z","shell.execute_reply.started":"2021-09-11T00:03:39.167651Z","shell.execute_reply":"2021-09-11T00:15:49.499659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Dropout Regularization","metadata":{}},{"cell_type":"code","source":"def train_data_dropout(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_dropout_regularization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:54:44.847806Z","iopub.execute_input":"2021-09-11T18:54:44.848154Z","iopub.status.idle":"2021-09-11T18:54:44.854928Z","shell.execute_reply.started":"2021-09-11T18:54:44.848119Z","shell.execute_reply":"2021-09-11T18:54:44.854074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout, accuracy = train_data_dropout(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_dropout.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:54:54.081217Z","iopub.execute_input":"2021-09-11T18:54:54.081564Z","iopub.status.idle":"2021-09-11T19:05:08.896065Z","shell.execute_reply.started":"2021-09-11T18:54:54.081534Z","shell.execute_reply":"2021-09-11T19:05:08.895014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Dropout Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_data_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_dropout_regularization_batch_normalization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T02:40:19.443466Z","iopub.execute_input":"2021-09-11T02:40:19.443819Z","iopub.status.idle":"2021-09-11T02:40:19.450071Z","shell.execute_reply.started":"2021-09-11T02:40:19.443786Z","shell.execute_reply":"2021-09-11T02:40:19.448832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T00:23:56.176352Z","iopub.execute_input":"2021-09-11T00:23:56.176676Z","iopub.status.idle":"2021-09-11T00:31:55.955568Z","shell.execute_reply.started":"2021-09-11T00:23:56.176645Z","shell.execute_reply":"2021-09-11T00:31:55.954811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.0001, 100)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T02:40:22.415594Z","iopub.execute_input":"2021-09-11T02:40:22.415926Z","iopub.status.idle":"2021-09-11T02:49:32.4353Z","shell.execute_reply.started":"2021-09-11T02:40:22.415896Z","shell.execute_reply":"2021-09-11T02:49:32.434532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T04:02:56.290021Z","iopub.execute_input":"2021-09-11T04:02:56.290352Z","iopub.status.idle":"2021-09-11T04:09:51.078461Z","shell.execute_reply.started":"2021-09-11T04:02:56.290317Z","shell.execute_reply":"2021-09-11T04:09:51.077667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Data Augmentation and Dropout Regularization","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation_dropout(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_dropout_regularization(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n\t# fit model  \n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:05:08.897833Z","iopub.execute_input":"2021-09-11T19:05:08.898389Z","iopub.status.idle":"2021-09-11T19:05:08.90552Z","shell.execute_reply.started":"2021-09-11T19:05:08.898347Z","shell.execute_reply":"2021-09-11T19:05:08.904733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout, accuracy = train_data_augmentation_dropout(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 50)\nprint(accuracy)\ny_pred = model_test_data_dropout.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:05:08.907065Z","iopub.execute_input":"2021-09-11T19:05:08.907529Z","iopub.status.idle":"2021-09-11T19:21:25.675911Z","shell.execute_reply.started":"2021-09-11T19:05:08.907492Z","shell.execute_reply":"2021-09-11T19:21:25.673979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_test_data_dropout.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:31:59.292342Z","iopub.execute_input":"2021-09-11T19:31:59.292672Z","iopub.status.idle":"2021-09-11T19:32:00.985407Z","shell.execute_reply.started":"2021-09-11T19:31:59.29264Z","shell.execute_reply":"2021-09-11T19:32:00.983987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Data with Data Augmentation, Dropout Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_dropout_regularization_batch_normalization(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n\t# fit model  \n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:32:25.177995Z","iopub.execute_input":"2021-09-11T19:32:25.178442Z","iopub.status.idle":"2021-09-11T19:32:25.185216Z","shell.execute_reply.started":"2021-09-11T19:32:25.178406Z","shell.execute_reply":"2021-09-11T19:32:25.184305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_augmentation_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 50)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:32:35.341419Z","iopub.execute_input":"2021-09-11T19:32:35.34174Z","iopub.status.idle":"2021-09-11T19:40:58.482794Z","shell.execute_reply.started":"2021-09-11T19:32:35.341708Z","shell.execute_reply":"2021-09-11T19:40:58.481965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_augmentation_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 50)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T02:49:32.445437Z","iopub.execute_input":"2021-09-11T02:49:32.445941Z","iopub.status.idle":"2021-09-11T04:02:56.288488Z","shell.execute_reply.started":"2021-09-11T02:49:32.445906Z","shell.execute_reply":"2021-09-11T04:02:56.28768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_dropout_batch_normalization, accuracy = train_data_augmentation_dropout_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.0001, 50)\nprint(accuracy)\ny_pred = model_test_data_dropout_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Weight Regularization","metadata":{}},{"cell_type":"code","source":"def train_data_weight(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_weight_regularization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:40:58.484912Z","iopub.execute_input":"2021-09-11T19:40:58.485284Z","iopub.status.idle":"2021-09-11T19:40:58.492211Z","shell.execute_reply.started":"2021-09-11T19:40:58.485246Z","shell.execute_reply":"2021-09-11T19:40:58.490208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_weight, accuracy = train_data_weight(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_weight.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T19:40:58.494273Z","iopub.execute_input":"2021-09-11T19:40:58.494629Z","iopub.status.idle":"2021-09-11T20:21:47.17684Z","shell.execute_reply.started":"2021-09-11T19:40:58.494593Z","shell.execute_reply":"2021-09-11T20:21:47.176069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Weight Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_weight_regularization_batch_normalization(learning_rate)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-12T00:32:19.301248Z","iopub.execute_input":"2021-09-12T00:32:19.301589Z","iopub.status.idle":"2021-09-12T00:32:19.309752Z","shell.execute_reply.started":"2021-09-12T00:32:19.301551Z","shell.execute_reply":"2021-09-12T00:32:19.308691Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T00:32:19.310954Z","iopub.execute_input":"2021-09-12T00:32:19.311506Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n157/157 [==============================] - 31s 183ms/step - loss: 25.2283 - accuracy: 0.8150 - val_loss: 26.5864 - val_accuracy: 0.5020\nEpoch 2/100\n157/157 [==============================] - 28s 178ms/step - loss: 24.8275 - accuracy: 0.9351 - val_loss: 26.7338 - val_accuracy: 0.5345\nEpoch 3/100\n157/157 [==============================] - 28s 178ms/step - loss: 24.5996 - accuracy: 0.9667 - val_loss: 25.1137 - val_accuracy: 0.7685\nEpoch 4/100\n157/157 [==============================] - 28s 178ms/step - loss: 24.4192 - accuracy: 0.9788 - val_loss: 24.3695 - val_accuracy: 0.9530\nEpoch 5/100\n157/157 [==============================] - 28s 178ms/step - loss: 24.2502 - accuracy: 0.9866 - val_loss: 24.2165 - val_accuracy: 0.9555\nEpoch 6/100\n157/157 [==============================] - 28s 178ms/step - loss: 24.0781 - accuracy: 0.9923 - val_loss: 24.0442 - val_accuracy: 0.9630\nEpoch 7/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.9173 - accuracy: 0.9964 - val_loss: 23.8882 - val_accuracy: 0.9655\nEpoch 8/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.7612 - accuracy: 0.9983 - val_loss: 23.7375 - val_accuracy: 0.9645\nEpoch 9/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.6177 - accuracy: 0.9966 - val_loss: 23.5879 - val_accuracy: 0.9705\nEpoch 10/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.4644 - accuracy: 0.9988 - val_loss: 23.4327 - val_accuracy: 0.9695\nEpoch 11/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.3156 - accuracy: 0.9990 - val_loss: 23.2930 - val_accuracy: 0.9725\nEpoch 12/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.1680 - accuracy: 0.9993 - val_loss: 23.1712 - val_accuracy: 0.9635\nEpoch 13/100\n157/157 [==============================] - 28s 178ms/step - loss: 23.0277 - accuracy: 0.9980 - val_loss: 23.0091 - val_accuracy: 0.9660\nEpoch 14/100\n157/157 [==============================] - 28s 178ms/step - loss: 22.8997 - accuracy: 0.9929 - val_loss: 22.8796 - val_accuracy: 0.9670\nEpoch 15/100\n157/157 [==============================] - 28s 178ms/step - loss: 22.7439 - accuracy: 0.9982 - val_loss: 22.7162 - val_accuracy: 0.9715\nEpoch 16/100\n157/157 [==============================] - 28s 178ms/step - loss: 22.5973 - accuracy: 0.9984 - val_loss: 22.5978 - val_accuracy: 0.9670\nEpoch 17/100\n157/157 [==============================] - 28s 178ms/step - loss: 22.4537 - accuracy: 0.9993 - val_loss: 22.4334 - val_accuracy: 0.9750\nEpoch 18/100\n102/157 [==================>...........] - ETA: 9s - loss: 22.3232 - accuracy: 1.0000","output_type":"stream"}]},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.01, 40)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:44:08.279897Z","iopub.execute_input":"2021-08-31T19:44:08.280178Z","iopub.status.idle":"2021-09-01T02:17:46.830578Z","shell.execute_reply.started":"2021-08-31T19:44:08.280153Z","shell.execute_reply":"2021-09-01T02:17:46.829361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.003, 40)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T02:26:47.447984Z","iopub.execute_input":"2021-09-01T02:26:47.448345Z","iopub.status.idle":"2021-09-01T09:02:24.23425Z","shell.execute_reply.started":"2021-09-01T02:26:47.448282Z","shell.execute_reply":"2021-09-01T09:02:24.232648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.002, 40)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T09:10:04.218182Z","iopub.execute_input":"2021-09-01T09:10:04.218641Z","iopub.status.idle":"2021-09-01T14:59:20.326823Z","shell.execute_reply.started":"2021-09-01T09:10:04.218603Z","shell.execute_reply":"2021-09-01T14:59:20.325484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.0009, 40)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T01:47:18.319856Z","iopub.execute_input":"2021-09-02T01:47:18.320148Z","iopub.status.idle":"2021-09-02T09:21:28.640654Z","shell.execute_reply.started":"2021-09-02T01:47:18.32012Z","shell.execute_reply":"2021-09-02T09:21:28.639328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_data_weight_batch2(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, regularization_lambda, epochs):\n  # define model\n  model = define_model_weight_regularization_batch_normalization2(learning_rate, regularization_lambda)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n  # fit model\n  history = model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-03T19:20:15.928044Z","iopub.execute_input":"2021-09-03T19:20:15.928417Z","iopub.status.idle":"2021-09-03T19:20:15.936059Z","shell.execute_reply.started":"2021-09-03T19:20:15.928386Z","shell.execute_reply":"2021-09-03T19:20:15.934899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_weight_batch_normalization, accuracy = train_data_weight_batch2(X_train, X_val, X_test, y_train, y_val, y_test, 0.0009, 0.001, 40)\nprint(accuracy)\ny_pred = model_test_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T19:20:18.164805Z","iopub.execute_input":"2021-09-03T19:20:18.165343Z","iopub.status.idle":"2021-09-04T03:44:32.422925Z","shell.execute_reply.started":"2021-09-03T19:20:18.165308Z","shell.execute_reply":"2021-09-04T03:44:32.421759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data with Data Augmentation and Weight Regularization","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation_weight(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_weight_regularization(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n\t# fit model  \n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.414199Z","iopub.execute_input":"2021-09-11T22:03:37.414561Z","iopub.status.idle":"2021-09-11T22:03:37.424684Z","shell.execute_reply.started":"2021-09-11T22:03:37.414496Z","shell.execute_reply":"2021-09-11T22:03:37.423936Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_test_data_weight, accuracy = train_data_augmentation_weight(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_weight.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T22:03:37.426036Z","iopub.execute_input":"2021-09-11T22:03:37.426500Z","iopub.status.idle":"2021-09-11T23:16:40.404110Z","shell.execute_reply.started":"2021-09-11T22:03:37.426465Z","shell.execute_reply":"2021-09-11T23:16:40.403281Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/100\n156/156 [==============================] - 59s 308ms/step - loss: 25.4824 - accuracy: 0.5727 - val_loss: 25.2048 - val_accuracy: 0.7735\nEpoch 2/100\n156/156 [==============================] - 44s 279ms/step - loss: 25.1848 - accuracy: 0.7364 - val_loss: 25.0560 - val_accuracy: 0.8140\nEpoch 3/100\n156/156 [==============================] - 44s 278ms/step - loss: 24.9747 - accuracy: 0.7967 - val_loss: 24.8463 - val_accuracy: 0.7935\nEpoch 4/100\n156/156 [==============================] - 43s 277ms/step - loss: 24.7399 - accuracy: 0.8448 - val_loss: 24.6199 - val_accuracy: 0.8440\nEpoch 5/100\n156/156 [==============================] - 43s 278ms/step - loss: 24.5736 - accuracy: 0.8505 - val_loss: 24.3704 - val_accuracy: 0.8835\nEpoch 6/100\n156/156 [==============================] - 44s 283ms/step - loss: 24.3419 - accuracy: 0.8755 - val_loss: 24.1674 - val_accuracy: 0.9065\nEpoch 7/100\n156/156 [==============================] - 44s 283ms/step - loss: 24.1567 - accuracy: 0.8958 - val_loss: 24.0484 - val_accuracy: 0.8880\nEpoch 8/100\n156/156 [==============================] - 44s 282ms/step - loss: 23.9924 - accuracy: 0.8980 - val_loss: 23.8127 - val_accuracy: 0.9295\nEpoch 9/100\n156/156 [==============================] - 45s 285ms/step - loss: 23.8080 - accuracy: 0.9160 - val_loss: 23.6762 - val_accuracy: 0.9325\nEpoch 10/100\n156/156 [==============================] - 44s 280ms/step - loss: 23.6357 - accuracy: 0.9270 - val_loss: 23.4876 - val_accuracy: 0.9420\nEpoch 11/100\n156/156 [==============================] - 44s 283ms/step - loss: 23.4623 - accuracy: 0.9394 - val_loss: 23.3402 - val_accuracy: 0.9495\nEpoch 12/100\n156/156 [==============================] - 43s 277ms/step - loss: 23.3157 - accuracy: 0.9409 - val_loss: 23.1879 - val_accuracy: 0.9455\nEpoch 13/100\n156/156 [==============================] - 43s 277ms/step - loss: 23.1586 - accuracy: 0.9471 - val_loss: 23.1257 - val_accuracy: 0.9160\nEpoch 14/100\n156/156 [==============================] - 43s 277ms/step - loss: 23.0083 - accuracy: 0.9481 - val_loss: 22.9801 - val_accuracy: 0.9135\nEpoch 15/100\n156/156 [==============================] - 43s 277ms/step - loss: 22.8812 - accuracy: 0.9437 - val_loss: 22.7635 - val_accuracy: 0.9460\nEpoch 16/100\n156/156 [==============================] - 44s 279ms/step - loss: 22.7275 - accuracy: 0.9505 - val_loss: 22.6639 - val_accuracy: 0.9290\nEpoch 17/100\n156/156 [==============================] - 44s 280ms/step - loss: 22.6008 - accuracy: 0.9444 - val_loss: 22.5416 - val_accuracy: 0.9205\nEpoch 18/100\n156/156 [==============================] - 43s 275ms/step - loss: 22.4702 - accuracy: 0.9371 - val_loss: 22.3357 - val_accuracy: 0.9495\nEpoch 19/100\n156/156 [==============================] - 43s 275ms/step - loss: 22.2978 - accuracy: 0.9520 - val_loss: 22.1986 - val_accuracy: 0.9510\nEpoch 20/100\n156/156 [==============================] - 44s 281ms/step - loss: 22.1417 - accuracy: 0.9620 - val_loss: 22.0333 - val_accuracy: 0.9635\nEpoch 21/100\n156/156 [==============================] - 43s 278ms/step - loss: 22.0067 - accuracy: 0.9605 - val_loss: 22.0044 - val_accuracy: 0.9220\nEpoch 22/100\n156/156 [==============================] - 43s 278ms/step - loss: 21.8761 - accuracy: 0.9592 - val_loss: 21.7596 - val_accuracy: 0.9650\nEpoch 23/100\n156/156 [==============================] - 44s 281ms/step - loss: 21.7317 - accuracy: 0.9634 - val_loss: 21.6745 - val_accuracy: 0.9480\nEpoch 24/100\n156/156 [==============================] - 43s 277ms/step - loss: 21.5927 - accuracy: 0.9643 - val_loss: 21.5064 - val_accuracy: 0.9580\nEpoch 25/100\n156/156 [==============================] - 43s 277ms/step - loss: 21.4817 - accuracy: 0.9566 - val_loss: 21.3886 - val_accuracy: 0.9475\nEpoch 26/100\n156/156 [==============================] - 43s 275ms/step - loss: 21.3281 - accuracy: 0.9639 - val_loss: 21.2233 - val_accuracy: 0.9645\nEpoch 27/100\n156/156 [==============================] - 43s 275ms/step - loss: 21.1903 - accuracy: 0.9679 - val_loss: 21.0913 - val_accuracy: 0.9720\nEpoch 28/100\n156/156 [==============================] - 43s 275ms/step - loss: 21.0533 - accuracy: 0.9683 - val_loss: 20.9629 - val_accuracy: 0.9670\nEpoch 29/100\n156/156 [==============================] - 44s 278ms/step - loss: 20.9185 - accuracy: 0.9697 - val_loss: 20.8445 - val_accuracy: 0.9670\nEpoch 30/100\n156/156 [==============================] - 43s 277ms/step - loss: 20.7960 - accuracy: 0.9684 - val_loss: 20.7381 - val_accuracy: 0.9495\nEpoch 31/100\n156/156 [==============================] - 43s 277ms/step - loss: 20.6631 - accuracy: 0.9695 - val_loss: 20.5693 - val_accuracy: 0.9690\nEpoch 32/100\n156/156 [==============================] - 44s 279ms/step - loss: 20.5244 - accuracy: 0.9734 - val_loss: 20.4406 - val_accuracy: 0.9680\nEpoch 33/100\n156/156 [==============================] - 43s 276ms/step - loss: 20.4083 - accuracy: 0.9699 - val_loss: 20.3399 - val_accuracy: 0.9600\nEpoch 34/100\n156/156 [==============================] - 43s 277ms/step - loss: 20.2751 - accuracy: 0.9713 - val_loss: 20.1865 - val_accuracy: 0.9675\nEpoch 35/100\n156/156 [==============================] - 43s 278ms/step - loss: 20.1462 - accuracy: 0.9732 - val_loss: 20.0621 - val_accuracy: 0.9750\nEpoch 36/100\n156/156 [==============================] - 43s 276ms/step - loss: 20.0192 - accuracy: 0.9763 - val_loss: 19.9424 - val_accuracy: 0.9710\nEpoch 37/100\n156/156 [==============================] - 43s 276ms/step - loss: 19.8990 - accuracy: 0.9746 - val_loss: 19.8385 - val_accuracy: 0.9620\nEpoch 38/100\n156/156 [==============================] - 44s 280ms/step - loss: 19.7808 - accuracy: 0.9711 - val_loss: 19.6991 - val_accuracy: 0.9710\nEpoch 39/100\n156/156 [==============================] - 43s 276ms/step - loss: 19.6414 - accuracy: 0.9775 - val_loss: 19.5725 - val_accuracy: 0.9715\nEpoch 40/100\n156/156 [==============================] - 43s 278ms/step - loss: 19.5269 - accuracy: 0.9770 - val_loss: 19.5135 - val_accuracy: 0.9510\nEpoch 41/100\n156/156 [==============================] - 44s 280ms/step - loss: 19.4175 - accuracy: 0.9706 - val_loss: 19.3473 - val_accuracy: 0.9655\nEpoch 42/100\n156/156 [==============================] - 44s 280ms/step - loss: 19.2801 - accuracy: 0.9802 - val_loss: 19.2129 - val_accuracy: 0.9715\nEpoch 43/100\n156/156 [==============================] - 43s 277ms/step - loss: 19.1682 - accuracy: 0.9761 - val_loss: 19.1542 - val_accuracy: 0.9515\nEpoch 44/100\n156/156 [==============================] - 43s 275ms/step - loss: 19.0490 - accuracy: 0.9779 - val_loss: 18.9721 - val_accuracy: 0.9720\nEpoch 45/100\n156/156 [==============================] - 43s 276ms/step - loss: 18.9186 - accuracy: 0.9820 - val_loss: 18.8653 - val_accuracy: 0.9690\nEpoch 46/100\n156/156 [==============================] - 43s 275ms/step - loss: 18.8059 - accuracy: 0.9797 - val_loss: 18.8125 - val_accuracy: 0.9445\nEpoch 47/100\n156/156 [==============================] - 43s 273ms/step - loss: 18.6949 - accuracy: 0.9784 - val_loss: 18.6235 - val_accuracy: 0.9730\nEpoch 48/100\n156/156 [==============================] - 43s 278ms/step - loss: 18.5704 - accuracy: 0.9810 - val_loss: 18.5043 - val_accuracy: 0.9765\nEpoch 49/100\n156/156 [==============================] - 43s 274ms/step - loss: 18.4641 - accuracy: 0.9753 - val_loss: 18.3886 - val_accuracy: 0.9700\nEpoch 50/100\n156/156 [==============================] - 43s 274ms/step - loss: 18.3465 - accuracy: 0.9794 - val_loss: 18.3109 - val_accuracy: 0.9580\nEpoch 51/100\n156/156 [==============================] - 43s 276ms/step - loss: 18.2369 - accuracy: 0.9768 - val_loss: 18.1727 - val_accuracy: 0.9750\nEpoch 52/100\n156/156 [==============================] - 43s 276ms/step - loss: 18.1138 - accuracy: 0.9820 - val_loss: 18.0771 - val_accuracy: 0.9630\nEpoch 53/100\n156/156 [==============================] - 43s 275ms/step - loss: 17.9983 - accuracy: 0.9827 - val_loss: 17.9441 - val_accuracy: 0.9750\nEpoch 54/100\n156/156 [==============================] - 43s 276ms/step - loss: 17.8879 - accuracy: 0.9847 - val_loss: 17.8295 - val_accuracy: 0.9730\nEpoch 55/100\n156/156 [==============================] - 43s 275ms/step - loss: 17.7954 - accuracy: 0.9750 - val_loss: 17.7153 - val_accuracy: 0.9790\nEpoch 56/100\n156/156 [==============================] - 43s 276ms/step - loss: 17.6732 - accuracy: 0.9790 - val_loss: 17.6160 - val_accuracy: 0.9695\nEpoch 57/100\n156/156 [==============================] - 44s 279ms/step - loss: 17.5619 - accuracy: 0.9807 - val_loss: 17.5188 - val_accuracy: 0.9615\nEpoch 58/100\n156/156 [==============================] - 45s 286ms/step - loss: 17.4515 - accuracy: 0.9814 - val_loss: 17.3842 - val_accuracy: 0.9785\nEpoch 59/100\n156/156 [==============================] - 45s 289ms/step - loss: 17.3434 - accuracy: 0.9799 - val_loss: 17.2833 - val_accuracy: 0.9785\nEpoch 60/100\n156/156 [==============================] - 43s 278ms/step - loss: 17.2350 - accuracy: 0.9829 - val_loss: 17.1701 - val_accuracy: 0.9800\nEpoch 61/100\n156/156 [==============================] - 43s 275ms/step - loss: 17.1278 - accuracy: 0.9831 - val_loss: 17.0633 - val_accuracy: 0.9785\nEpoch 62/100\n156/156 [==============================] - 43s 277ms/step - loss: 17.0209 - accuracy: 0.9818 - val_loss: 16.9538 - val_accuracy: 0.9795\nEpoch 63/100\n156/156 [==============================] - 43s 278ms/step - loss: 16.9171 - accuracy: 0.9825 - val_loss: 16.8532 - val_accuracy: 0.9790\nEpoch 64/100\n156/156 [==============================] - 43s 278ms/step - loss: 16.8209 - accuracy: 0.9805 - val_loss: 16.7471 - val_accuracy: 0.9795\nEpoch 65/100\n156/156 [==============================] - 44s 281ms/step - loss: 16.7104 - accuracy: 0.9818 - val_loss: 16.6399 - val_accuracy: 0.9800\nEpoch 66/100\n156/156 [==============================] - 43s 278ms/step - loss: 16.5975 - accuracy: 0.9867 - val_loss: 16.5396 - val_accuracy: 0.9785\nEpoch 67/100\n156/156 [==============================] - 44s 280ms/step - loss: 16.5099 - accuracy: 0.9799 - val_loss: 16.4342 - val_accuracy: 0.9795\nEpoch 68/100\n156/156 [==============================] - 43s 278ms/step - loss: 16.3929 - accuracy: 0.9865 - val_loss: 16.3465 - val_accuracy: 0.9770\nEpoch 69/100\n156/156 [==============================] - 44s 280ms/step - loss: 16.3001 - accuracy: 0.9823 - val_loss: 16.2554 - val_accuracy: 0.9695\nEpoch 70/100\n156/156 [==============================] - 44s 284ms/step - loss: 16.1961 - accuracy: 0.9824 - val_loss: 16.1397 - val_accuracy: 0.9775\nEpoch 71/100\n156/156 [==============================] - 44s 280ms/step - loss: 16.1045 - accuracy: 0.9813 - val_loss: 16.0464 - val_accuracy: 0.9735\nEpoch 72/100\n156/156 [==============================] - 44s 279ms/step - loss: 16.0002 - accuracy: 0.9813 - val_loss: 15.9318 - val_accuracy: 0.9780\nEpoch 73/100\n156/156 [==============================] - 45s 285ms/step - loss: 15.8904 - accuracy: 0.9846 - val_loss: 15.8371 - val_accuracy: 0.9780\nEpoch 74/100\n156/156 [==============================] - 44s 279ms/step - loss: 15.7996 - accuracy: 0.9827 - val_loss: 15.7399 - val_accuracy: 0.9805\nEpoch 75/100\n156/156 [==============================] - 44s 279ms/step - loss: 15.6939 - accuracy: 0.9878 - val_loss: 15.6547 - val_accuracy: 0.9730\nEpoch 76/100\n156/156 [==============================] - 44s 284ms/step - loss: 15.6044 - accuracy: 0.9846 - val_loss: 15.5459 - val_accuracy: 0.9775\nEpoch 77/100\n156/156 [==============================] - 44s 283ms/step - loss: 15.5109 - accuracy: 0.9808 - val_loss: 15.4528 - val_accuracy: 0.9785\nEpoch 78/100\n156/156 [==============================] - 44s 279ms/step - loss: 15.4056 - accuracy: 0.9874 - val_loss: 15.4074 - val_accuracy: 0.9625\nEpoch 79/100\n156/156 [==============================] - 44s 283ms/step - loss: 15.3147 - accuracy: 0.9825 - val_loss: 15.2598 - val_accuracy: 0.9800\nEpoch 80/100\n156/156 [==============================] - 44s 283ms/step - loss: 15.2123 - accuracy: 0.9887 - val_loss: 15.1679 - val_accuracy: 0.9780\nEpoch 81/100\n156/156 [==============================] - 44s 279ms/step - loss: 15.1234 - accuracy: 0.9846 - val_loss: 15.0902 - val_accuracy: 0.9745\nEpoch 82/100\n156/156 [==============================] - 44s 284ms/step - loss: 15.0266 - accuracy: 0.9875 - val_loss: 14.9972 - val_accuracy: 0.9735\nEpoch 83/100\n156/156 [==============================] - 44s 283ms/step - loss: 14.9404 - accuracy: 0.9828 - val_loss: 14.8750 - val_accuracy: 0.9835\nEpoch 84/100\n156/156 [==============================] - 44s 283ms/step - loss: 14.8470 - accuracy: 0.9843 - val_loss: 14.7935 - val_accuracy: 0.9780\nEpoch 85/100\n156/156 [==============================] - 45s 285ms/step - loss: 14.7508 - accuracy: 0.9863 - val_loss: 14.7013 - val_accuracy: 0.9810\nEpoch 86/100\n156/156 [==============================] - 44s 279ms/step - loss: 14.6579 - accuracy: 0.9884 - val_loss: 14.6264 - val_accuracy: 0.9745\nEpoch 87/100\n156/156 [==============================] - 44s 280ms/step - loss: 14.5642 - accuracy: 0.9881 - val_loss: 14.5170 - val_accuracy: 0.9815\nEpoch 88/100\n156/156 [==============================] - 44s 281ms/step - loss: 14.4820 - accuracy: 0.9855 - val_loss: 14.4583 - val_accuracy: 0.9690\nEpoch 89/100\n156/156 [==============================] - 44s 281ms/step - loss: 14.3904 - accuracy: 0.9869 - val_loss: 14.3314 - val_accuracy: 0.9830\nEpoch 90/100\n156/156 [==============================] - 44s 282ms/step - loss: 14.2975 - accuracy: 0.9862 - val_loss: 14.2623 - val_accuracy: 0.9780\nEpoch 91/100\n156/156 [==============================] - 44s 283ms/step - loss: 14.2154 - accuracy: 0.9868 - val_loss: 14.1621 - val_accuracy: 0.9820\nEpoch 92/100\n156/156 [==============================] - 44s 280ms/step - loss: 14.1284 - accuracy: 0.9846 - val_loss: 14.0738 - val_accuracy: 0.9825\nEpoch 93/100\n156/156 [==============================] - 43s 278ms/step - loss: 14.0376 - accuracy: 0.9859 - val_loss: 13.9934 - val_accuracy: 0.9785\nEpoch 94/100\n156/156 [==============================] - 44s 280ms/step - loss: 13.9464 - accuracy: 0.9881 - val_loss: 13.9336 - val_accuracy: 0.9695\nEpoch 95/100\n156/156 [==============================] - 43s 277ms/step - loss: 13.8695 - accuracy: 0.9839 - val_loss: 13.8095 - val_accuracy: 0.9830\nEpoch 96/100\n156/156 [==============================] - 43s 278ms/step - loss: 13.7722 - accuracy: 0.9903 - val_loss: 13.7421 - val_accuracy: 0.9800\nEpoch 97/100\n156/156 [==============================] - 44s 282ms/step - loss: 13.6835 - accuracy: 0.9900 - val_loss: 13.6404 - val_accuracy: 0.9820\nEpoch 98/100\n156/156 [==============================] - 44s 280ms/step - loss: 13.6003 - accuracy: 0.9894 - val_loss: 13.5625 - val_accuracy: 0.9810\nEpoch 99/100\n156/156 [==============================] - 44s 280ms/step - loss: 13.5189 - accuracy: 0.9883 - val_loss: 13.4841 - val_accuracy: 0.9810\nEpoch 100/100\n156/156 [==============================] - 44s 282ms/step - loss: 13.4409 - accuracy: 0.9869 - val_loss: 13.3993 - val_accuracy: 0.9810\n63/63 [==============================] - 2s 24ms/step - loss: 13.3860 - accuracy: 0.9845\n0.984499990940094\n986 14 17 983\nTPR/Recall: 0.983\nTNR/Specificity: 0.986\nPPV/Precision: 0.9859578736208626\nNPV: 0.9830508474576272\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Train Data with Data Augmentation, Weight Regularization and Batch Normalization","metadata":{}},{"cell_type":"code","source":"def train_data_augmentation_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, learning_rate, epochs):\n  # define model\n  model = define_model_weight_regularization_batch_normalization(learning_rate)\n  # create data generator\n  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n  # prepare iterator\n  it_train = datagen.flow(X_train, y_train, batch_size=64)\n  # define early stopping\n  es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', min_delta=0, patience=5, verbose=1)\n\t# fit model  \n  steps = int(X_train.shape[0] / 64)\n  history = model.fit(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_val, y_val), verbose=1, callbacks=[es])\n  # plot model diagnostics\n  summarize_diagnostics(history)\n  # evaluate model\n  _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n  return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-11T23:16:40.405448Z","iopub.execute_input":"2021-09-11T23:16:40.405854Z","iopub.status.idle":"2021-09-11T23:16:40.415133Z","shell.execute_reply.started":"2021-09-11T23:16:40.405801Z","shell.execute_reply":"2021-09-11T23:16:40.414368Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_test_data_weight_batch_normalization, accuracy = train_data_augmentation_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.001, 100)\nprint(accuracy)\ny_pred = model_test_data_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T23:16:40.417024Z","iopub.execute_input":"2021-09-11T23:16:40.417531Z","iopub.status.idle":"2021-09-12T00:32:19.299844Z","shell.execute_reply.started":"2021-09-11T23:16:40.417476Z","shell.execute_reply":"2021-09-12T00:32:19.299071Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/100\n156/156 [==============================] - 49s 300ms/step - loss: 25.2550 - accuracy: 0.8040 - val_loss: 27.0506 - val_accuracy: 0.5025\nEpoch 2/100\n156/156 [==============================] - 47s 298ms/step - loss: 24.8519 - accuracy: 0.9292 - val_loss: 25.9284 - val_accuracy: 0.5710\nEpoch 3/100\n156/156 [==============================] - 47s 299ms/step - loss: 24.6734 - accuracy: 0.9387 - val_loss: 24.6180 - val_accuracy: 0.9230\nEpoch 4/100\n156/156 [==============================] - 47s 302ms/step - loss: 24.4909 - accuracy: 0.9505 - val_loss: 24.4053 - val_accuracy: 0.9370\nEpoch 5/100\n156/156 [==============================] - 46s 292ms/step - loss: 24.3195 - accuracy: 0.9601 - val_loss: 24.3240 - val_accuracy: 0.9265\nEpoch 6/100\n156/156 [==============================] - 46s 296ms/step - loss: 24.1546 - accuracy: 0.9660 - val_loss: 24.0953 - val_accuracy: 0.9485\nEpoch 7/100\n156/156 [==============================] - 45s 291ms/step - loss: 24.0041 - accuracy: 0.9673 - val_loss: 23.9190 - val_accuracy: 0.9605\nEpoch 8/100\n156/156 [==============================] - 46s 293ms/step - loss: 23.8417 - accuracy: 0.9726 - val_loss: 23.7563 - val_accuracy: 0.9625\nEpoch 9/100\n156/156 [==============================] - 46s 291ms/step - loss: 23.6818 - accuracy: 0.9777 - val_loss: 23.5868 - val_accuracy: 0.9700\nEpoch 10/100\n156/156 [==============================] - 46s 295ms/step - loss: 23.5379 - accuracy: 0.9752 - val_loss: 23.4630 - val_accuracy: 0.9625\nEpoch 11/100\n156/156 [==============================] - 47s 298ms/step - loss: 23.3813 - accuracy: 0.9808 - val_loss: 23.3672 - val_accuracy: 0.9445\nEpoch 12/100\n156/156 [==============================] - 46s 292ms/step - loss: 23.2359 - accuracy: 0.9802 - val_loss: 23.1563 - val_accuracy: 0.9725\nEpoch 13/100\n156/156 [==============================] - 46s 295ms/step - loss: 23.0972 - accuracy: 0.9793 - val_loss: 23.0982 - val_accuracy: 0.9455\nEpoch 14/100\n156/156 [==============================] - 45s 291ms/step - loss: 22.9404 - accuracy: 0.9834 - val_loss: 22.8846 - val_accuracy: 0.9675\nEpoch 15/100\n156/156 [==============================] - 46s 297ms/step - loss: 22.7919 - accuracy: 0.9858 - val_loss: 22.7035 - val_accuracy: 0.9750\nEpoch 16/100\n156/156 [==============================] - 46s 292ms/step - loss: 22.6530 - accuracy: 0.9859 - val_loss: 22.5807 - val_accuracy: 0.9760\nEpoch 17/100\n156/156 [==============================] - 46s 293ms/step - loss: 22.5054 - accuracy: 0.9883 - val_loss: 22.4849 - val_accuracy: 0.9615\nEpoch 18/100\n156/156 [==============================] - 47s 298ms/step - loss: 22.3656 - accuracy: 0.9869 - val_loss: 22.3214 - val_accuracy: 0.9730\nEpoch 19/100\n156/156 [==============================] - 46s 295ms/step - loss: 22.2306 - accuracy: 0.9859 - val_loss: 22.4163 - val_accuracy: 0.9135\nEpoch 20/100\n156/156 [==============================] - 46s 299ms/step - loss: 22.0897 - accuracy: 0.9882 - val_loss: 22.0384 - val_accuracy: 0.9700\nEpoch 21/100\n156/156 [==============================] - 46s 295ms/step - loss: 21.9593 - accuracy: 0.9831 - val_loss: 21.9309 - val_accuracy: 0.9595\nEpoch 22/100\n156/156 [==============================] - 46s 295ms/step - loss: 21.8118 - accuracy: 0.9884 - val_loss: 21.7919 - val_accuracy: 0.9670\nEpoch 23/100\n156/156 [==============================] - 46s 297ms/step - loss: 21.6796 - accuracy: 0.9865 - val_loss: 21.6532 - val_accuracy: 0.9660\nEpoch 24/100\n156/156 [==============================] - 46s 295ms/step - loss: 21.5409 - accuracy: 0.9899 - val_loss: 21.8232 - val_accuracy: 0.8610\nEpoch 25/100\n156/156 [==============================] - 46s 297ms/step - loss: 21.4117 - accuracy: 0.9878 - val_loss: 21.3467 - val_accuracy: 0.9775\nEpoch 26/100\n156/156 [==============================] - 46s 293ms/step - loss: 21.2685 - accuracy: 0.9934 - val_loss: 21.2243 - val_accuracy: 0.9755\nEpoch 27/100\n156/156 [==============================] - 46s 293ms/step - loss: 21.1388 - accuracy: 0.9930 - val_loss: 21.0866 - val_accuracy: 0.9805\nEpoch 28/100\n156/156 [==============================] - 46s 295ms/step - loss: 21.0089 - accuracy: 0.9907 - val_loss: 20.9872 - val_accuracy: 0.9665\nEpoch 29/100\n156/156 [==============================] - 45s 288ms/step - loss: 20.8725 - accuracy: 0.9936 - val_loss: 20.8245 - val_accuracy: 0.9790\nEpoch 30/100\n156/156 [==============================] - 46s 291ms/step - loss: 20.7499 - accuracy: 0.9906 - val_loss: 20.7301 - val_accuracy: 0.9665\nEpoch 31/100\n156/156 [==============================] - 45s 287ms/step - loss: 20.6329 - accuracy: 0.9859 - val_loss: 20.5944 - val_accuracy: 0.9700\nEpoch 32/100\n156/156 [==============================] - 45s 287ms/step - loss: 20.4871 - accuracy: 0.9936 - val_loss: 20.4437 - val_accuracy: 0.9775\nEpoch 33/100\n156/156 [==============================] - 45s 290ms/step - loss: 20.3544 - accuracy: 0.9959 - val_loss: 20.3150 - val_accuracy: 0.9805\nEpoch 34/100\n156/156 [==============================] - 45s 286ms/step - loss: 20.2317 - accuracy: 0.9936 - val_loss: 20.1804 - val_accuracy: 0.9810\nEpoch 35/100\n156/156 [==============================] - 45s 290ms/step - loss: 20.1110 - accuracy: 0.9925 - val_loss: 20.0563 - val_accuracy: 0.9805\nEpoch 36/100\n156/156 [==============================] - 45s 285ms/step - loss: 19.9822 - accuracy: 0.9949 - val_loss: 19.9350 - val_accuracy: 0.9810\nEpoch 37/100\n156/156 [==============================] - 45s 286ms/step - loss: 19.8536 - accuracy: 0.9962 - val_loss: 19.8157 - val_accuracy: 0.9785\nEpoch 38/100\n156/156 [==============================] - 45s 290ms/step - loss: 19.7352 - accuracy: 0.9940 - val_loss: 19.6770 - val_accuracy: 0.9820\nEpoch 39/100\n156/156 [==============================] - 45s 288ms/step - loss: 19.6133 - accuracy: 0.9936 - val_loss: 19.6002 - val_accuracy: 0.9710\nEpoch 40/100\n156/156 [==============================] - 45s 287ms/step - loss: 19.4880 - accuracy: 0.9951 - val_loss: 19.4507 - val_accuracy: 0.9790\nEpoch 41/100\n156/156 [==============================] - 45s 290ms/step - loss: 19.3641 - accuracy: 0.9963 - val_loss: 19.3657 - val_accuracy: 0.9630\nEpoch 42/100\n156/156 [==============================] - 45s 290ms/step - loss: 19.2446 - accuracy: 0.9959 - val_loss: 19.2724 - val_accuracy: 0.9630\nEpoch 43/100\n156/156 [==============================] - 45s 289ms/step - loss: 19.1252 - accuracy: 0.9964 - val_loss: 19.0924 - val_accuracy: 0.9815\nEpoch 44/100\n156/156 [==============================] - 45s 286ms/step - loss: 19.0104 - accuracy: 0.9952 - val_loss: 18.9708 - val_accuracy: 0.9805\nEpoch 45/100\n156/156 [==============================] - 45s 291ms/step - loss: 18.8882 - accuracy: 0.9962 - val_loss: 18.8809 - val_accuracy: 0.9740\nEpoch 46/100\n156/156 [==============================] - 45s 290ms/step - loss: 18.7699 - accuracy: 0.9966 - val_loss: 18.7639 - val_accuracy: 0.9680\nEpoch 47/100\n156/156 [==============================] - 45s 287ms/step - loss: 18.6571 - accuracy: 0.9955 - val_loss: 18.6250 - val_accuracy: 0.9785\nEpoch 48/100\n156/156 [==============================] - 46s 292ms/step - loss: 18.5384 - accuracy: 0.9966 - val_loss: 18.4950 - val_accuracy: 0.9840\nEpoch 49/100\n156/156 [==============================] - 45s 287ms/step - loss: 18.4233 - accuracy: 0.9967 - val_loss: 18.3771 - val_accuracy: 0.9820\nEpoch 50/100\n156/156 [==============================] - 45s 286ms/step - loss: 18.3072 - accuracy: 0.9965 - val_loss: 18.2759 - val_accuracy: 0.9825\nEpoch 51/100\n156/156 [==============================] - 45s 289ms/step - loss: 18.1927 - accuracy: 0.9978 - val_loss: 18.1869 - val_accuracy: 0.9725\nEpoch 52/100\n156/156 [==============================] - 44s 283ms/step - loss: 18.0797 - accuracy: 0.9976 - val_loss: 18.0475 - val_accuracy: 0.9845\nEpoch 53/100\n156/156 [==============================] - 45s 288ms/step - loss: 17.9645 - accuracy: 0.9986 - val_loss: 17.9748 - val_accuracy: 0.9730\nEpoch 54/100\n156/156 [==============================] - 45s 285ms/step - loss: 17.8528 - accuracy: 0.9982 - val_loss: 17.8420 - val_accuracy: 0.9770\nEpoch 55/100\n156/156 [==============================] - 45s 285ms/step - loss: 17.7447 - accuracy: 0.9972 - val_loss: 17.7089 - val_accuracy: 0.9825\nEpoch 56/100\n156/156 [==============================] - 45s 290ms/step - loss: 17.6316 - accuracy: 0.9986 - val_loss: 17.5955 - val_accuracy: 0.9855\nEpoch 57/100\n156/156 [==============================] - 45s 287ms/step - loss: 17.5239 - accuracy: 0.9974 - val_loss: 17.5312 - val_accuracy: 0.9740\nEpoch 58/100\n156/156 [==============================] - 45s 287ms/step - loss: 17.4133 - accuracy: 0.9981 - val_loss: 17.3981 - val_accuracy: 0.9785\nEpoch 59/100\n156/156 [==============================] - 45s 288ms/step - loss: 17.3055 - accuracy: 0.9985 - val_loss: 17.2911 - val_accuracy: 0.9775\nEpoch 60/100\n156/156 [==============================] - 45s 287ms/step - loss: 17.2020 - accuracy: 0.9962 - val_loss: 17.3738 - val_accuracy: 0.9440\nEpoch 61/100\n156/156 [==============================] - 45s 290ms/step - loss: 17.0960 - accuracy: 0.9966 - val_loss: 17.0839 - val_accuracy: 0.9795\nEpoch 62/100\n156/156 [==============================] - 45s 287ms/step - loss: 16.9876 - accuracy: 0.9972 - val_loss: 16.9912 - val_accuracy: 0.9775\nEpoch 63/100\n156/156 [==============================] - 45s 286ms/step - loss: 16.8837 - accuracy: 0.9966 - val_loss: 16.9146 - val_accuracy: 0.9690\nEpoch 64/100\n156/156 [==============================] - 45s 291ms/step - loss: 16.7785 - accuracy: 0.9974 - val_loss: 16.7601 - val_accuracy: 0.9815\nEpoch 65/100\n156/156 [==============================] - 45s 285ms/step - loss: 16.6698 - accuracy: 0.9983 - val_loss: 16.7120 - val_accuracy: 0.9700\nEpoch 66/100\n156/156 [==============================] - 45s 287ms/step - loss: 16.5683 - accuracy: 0.9982 - val_loss: 16.6298 - val_accuracy: 0.9630\nEpoch 67/100\n156/156 [==============================] - 45s 289ms/step - loss: 16.4651 - accuracy: 0.9982 - val_loss: 16.4572 - val_accuracy: 0.9810\nEpoch 68/100\n156/156 [==============================] - 45s 286ms/step - loss: 16.3609 - accuracy: 0.9983 - val_loss: 16.3650 - val_accuracy: 0.9800\nEpoch 69/100\n156/156 [==============================] - 45s 289ms/step - loss: 16.2674 - accuracy: 0.9962 - val_loss: 16.2808 - val_accuracy: 0.9745\nEpoch 70/100\n156/156 [==============================] - 45s 287ms/step - loss: 16.1624 - accuracy: 0.9972 - val_loss: 16.2642 - val_accuracy: 0.9580\nEpoch 71/100\n156/156 [==============================] - 45s 285ms/step - loss: 16.0623 - accuracy: 0.9975 - val_loss: 16.0894 - val_accuracy: 0.9765\nEpoch 72/100\n156/156 [==============================] - 45s 288ms/step - loss: 15.9585 - accuracy: 0.9983 - val_loss: 15.9481 - val_accuracy: 0.9820\nEpoch 73/100\n156/156 [==============================] - 45s 287ms/step - loss: 15.8591 - accuracy: 0.9986 - val_loss: 15.8710 - val_accuracy: 0.9740\nEpoch 74/100\n156/156 [==============================] - 45s 288ms/step - loss: 15.7626 - accuracy: 0.9980 - val_loss: 15.7841 - val_accuracy: 0.9740\nEpoch 75/100\n156/156 [==============================] - 45s 285ms/step - loss: 15.6642 - accuracy: 0.9981 - val_loss: 15.6954 - val_accuracy: 0.9745\nEpoch 76/100\n156/156 [==============================] - 45s 285ms/step - loss: 15.5680 - accuracy: 0.9977 - val_loss: 15.5988 - val_accuracy: 0.9730\nEpoch 77/100\n156/156 [==============================] - 45s 289ms/step - loss: 15.4809 - accuracy: 0.9951 - val_loss: 15.4854 - val_accuracy: 0.9780\nEpoch 78/100\n156/156 [==============================] - 45s 286ms/step - loss: 15.3792 - accuracy: 0.9965 - val_loss: 15.4134 - val_accuracy: 0.9740\nEpoch 79/100\n156/156 [==============================] - 45s 286ms/step - loss: 15.2837 - accuracy: 0.9963 - val_loss: 15.2981 - val_accuracy: 0.9765\nEpoch 80/100\n156/156 [==============================] - 45s 286ms/step - loss: 15.1832 - accuracy: 0.9982 - val_loss: 15.1767 - val_accuracy: 0.9810\nEpoch 81/100\n156/156 [==============================] - 45s 286ms/step - loss: 15.0885 - accuracy: 0.9986 - val_loss: 15.1154 - val_accuracy: 0.9735\nEpoch 82/100\n156/156 [==============================] - 45s 290ms/step - loss: 14.9976 - accuracy: 0.9982 - val_loss: 15.0721 - val_accuracy: 0.9595\nEpoch 83/100\n156/156 [==============================] - 45s 289ms/step - loss: 14.9051 - accuracy: 0.9975 - val_loss: 14.9068 - val_accuracy: 0.9825\nEpoch 84/100\n156/156 [==============================] - 45s 288ms/step - loss: 14.8091 - accuracy: 0.9983 - val_loss: 14.8421 - val_accuracy: 0.9720\nEpoch 85/100\n156/156 [==============================] - 45s 287ms/step - loss: 14.7150 - accuracy: 0.9998 - val_loss: 14.7456 - val_accuracy: 0.9765\nEpoch 86/100\n156/156 [==============================] - 45s 287ms/step - loss: 14.6264 - accuracy: 0.9982 - val_loss: 14.6481 - val_accuracy: 0.9745\nEpoch 87/100\n156/156 [==============================] - 46s 296ms/step - loss: 14.5425 - accuracy: 0.9957 - val_loss: 14.6764 - val_accuracy: 0.9345\nEpoch 88/100\n156/156 [==============================] - 45s 287ms/step - loss: 14.4494 - accuracy: 0.9967 - val_loss: 14.4655 - val_accuracy: 0.9735\nEpoch 89/100\n156/156 [==============================] - 45s 288ms/step - loss: 14.3657 - accuracy: 0.9951 - val_loss: 14.3595 - val_accuracy: 0.9805\nEpoch 90/100\n156/156 [==============================] - 45s 286ms/step - loss: 14.2676 - accuracy: 0.9984 - val_loss: 14.2532 - val_accuracy: 0.9850\nEpoch 91/100\n156/156 [==============================] - 45s 286ms/step - loss: 14.1777 - accuracy: 0.9985 - val_loss: 14.2049 - val_accuracy: 0.9770\nEpoch 92/100\n156/156 [==============================] - 45s 288ms/step - loss: 14.0894 - accuracy: 0.9988 - val_loss: 14.0928 - val_accuracy: 0.9815\nEpoch 93/100\n156/156 [==============================] - 45s 287ms/step - loss: 14.0075 - accuracy: 0.9967 - val_loss: 14.0373 - val_accuracy: 0.9785\nEpoch 94/100\n156/156 [==============================] - 45s 288ms/step - loss: 13.9203 - accuracy: 0.9963 - val_loss: 13.9808 - val_accuracy: 0.9660\nEpoch 95/100\n156/156 [==============================] - 45s 291ms/step - loss: 13.8317 - accuracy: 0.9975 - val_loss: 13.8450 - val_accuracy: 0.9795\nEpoch 96/100\n156/156 [==============================] - 45s 289ms/step - loss: 13.7425 - accuracy: 0.9987 - val_loss: 13.7517 - val_accuracy: 0.9780\nEpoch 97/100\n156/156 [==============================] - 45s 289ms/step - loss: 13.6611 - accuracy: 0.9976 - val_loss: 13.7358 - val_accuracy: 0.9655\nEpoch 98/100\n156/156 [==============================] - 45s 289ms/step - loss: 13.5727 - accuracy: 0.9989 - val_loss: 13.6368 - val_accuracy: 0.9685\nEpoch 99/100\n156/156 [==============================] - 45s 289ms/step - loss: 13.4898 - accuracy: 0.9978 - val_loss: 13.5145 - val_accuracy: 0.9775\nEpoch 100/100\n156/156 [==============================] - 45s 291ms/step - loss: 13.4043 - accuracy: 0.9986 - val_loss: 13.4047 - val_accuracy: 0.9830\n63/63 [==============================] - 2s 27ms/step - loss: 13.3673 - accuracy: 0.9915\n0.9915000200271606\n992 8 9 991\nTPR/Recall: 0.991\nTNR/Specificity: 0.992\nPPV/Precision: 0.991991991991992\nNPV: 0.991008991008991\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYEAAAEUCAYAAADN8orUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABk3ElEQVR4nO3dd3gU1d7A8e9sT28kgYQUEpJAQgidUARCbyJFRaUoongFFOWqlOvVi42L5SICggVRinIvShMBX5CqUpTeWyANCCFtN3XbvH+sWVhCSSAQyJ7P8+TJs1PPmbM7v5lzzpyRZFmWEQRBEJySoroTIAiCIFQfEQQEQRCcmAgCgiAITkwEAUEQBCcmgoAgCIITE0FAEATBiYkgIAiC4MRU1Z0A4d6Sk5PDV199xaZNm8jIyECWZUJDQ+nYsSPDhg0jMDCwupNYITExMded17t3b6ZPn16p7RUXF/Pll1/SqlUrWrdufbvJqzbDhg0jKyuLdevWVXdShHuECAKC3eHDh3n22WcxGAz07duXIUOGoFAoOH78OEuXLmX9+vX8/PPP1Z3MCktMTGTgwIHlpgcHB1d6W8XFxcyaNYuxY8fe10FAEK4mgoAAgMFgYMyYMQAsW7aMqKgoh/njx4/niy++uOE2iouLcXFxuWNprKywsDAeeuihatl3UVERrq6u1bJvQagM0SYgALBkyRLOnz/PhAkTygUAAA8PD8aPH2//PGzYMHr27MnRo0cZNmwYTZo0YcqUKYAtGEybNo1OnTrRqFEjunfvzueff47VanXY5vbt2xkyZAgtW7YkISGBrl278tZbbzkss3jxYh588EGaNGlC8+bNeeihh1iyZEmV5XvixInEx8eTmZnJ6NGjadq0KYmJiUybNg2LxQJAeno6bdq0AWDWrFnExMQQExPDxIkTAZg5cyYxMTGcOHGCV199lVatWtG3b1/7Pr777jv69u1LfHw87dq144033iAvL88hHWXH89ixYzzxxBMkJCTQqVMn5s2bZ1/GarXSqVMn/va3v5XLh9lspm3btrz00ktVclwqkuaUlBTGjRtH+/btadSoEe3bt+eFF17g4sWL9mUqUsZC9RJ3AgIAGzduRKvV0qtXrwqvYzAYGDlyJN27d6dv3754eHggyzJjxozht99+Y9CgQcTFxbFjxw4++ugj0tPT7SeAU6dOMWrUKKKjoxk7diwuLi6kpqby66+/2re/dOlS3nrrLXr06MGQIUMwm82cPHmSvXv38thjj900fUajkZycnHLT3dzc0Gq19s+yLPPMM88QHx/Pa6+9xvbt2/nqq68ICQnhiSeewNfXl3/961/861//olu3bnTr1g2A0NBQh+2+/PLL1K1bl3HjxmEymQD49NNPmTFjBomJiQwePJjU1FS+/fZb9u/fz9KlS9FoNPb1CwoKGDlyJF27dqV379788ssvvP/++1gsFkaNGoVCoaBfv3589dVX5Obm4uPjY1/3t99+Izs7m/79+1eg5G6sImk2mUyMHDmSkpISnnjiCfz9/cnKymLbtm1cvHiRgICACpWxcA+QBUGW5ZYtW8r9+vWr8PJDhw6Vo6Oj5W+++cZh+oYNG+To6Gh55syZDtMnTpwoR0dHy8ePH5dlWZa//vprOTo6Ws7Ozr7uPkaPHi336dOnErm4LDo6+rp/3377rX25CRMmXDO9/fv3lwcMGGD/nJ2dLUdHR8uffPJJuX198skncnR0tDx27FiH6dnZ2XJcXJz85JNPymaz2T79hx9+kKOjo+WFCxfap5Udz7lz59qnmc1meejQoXJCQoKs1+tlWZblU6dOydHR0fKiRYsc9jV+/Hg5MTFRNplMNzwuQ4cOlXv06HHd+RVN89GjR+Xo6Gh57dq1191WRcpYqH6iOkgAbFehbm5ulVpHpVIxePBgh2lbtmxBoVAwfPhwh+kjRowAYPPmzYCtegngl19+KVdNVMbDw4MLFy5w4MCBSqWrTFJSEvPnzy/317lz53LLPvroow6fmzdvTnp6eqX29/jjjzt8/v333zGZTAwfPhylUmmf/tBDD1GrVi37sSijUCgYMmSI/bNSqWTIkCEUFxezc+dOACIjI2ncuDGrVq2yL1dYWMgvv/xCnz59UKlu7+a+omku+678+uuvFBUVXXNbFSljofqJICAA4O7uTmFhYaXWCQgIcKhWAcjIyMDPzw9PT0+H6fXq1UOhUJCRkQHYumk2b96c119/nTZt2jBu3Dh+/PFHzGazfZ1nn30WNzc3HnnkEbp27cobb7zBjh07KpW+tm3blvu7upurWq0mICDAYZqXlxf5+fkV3hdASEiIw+dz587Z834lpVJJWFiY/ViU8fPzw93d3WFaeHg4gENA6t+/P/v27SM1NRWA9evXU1xcXCWN4BVNc0hICCNGjGDp0qUkJiby1FNP8c0335Cbm2tfpyJlLFQ/EQQEACIiIjhz5gxGo7HC61wdACpDp9OxaNEiFixYwKBBgzhz5gyvvPIKjz76KCUlJYDtqnfdunX2+unNmzfz5JNP2hugq4okSVWyHZ1OVyXbuZk+ffqgVqvtdwOrVq0iIiKC+Pj4u7L/MhMnTmT16tWMGTMGi8XCtGnT6NWrF6dOnQIqVsZC9RNBQACgc+fOlJaW3vZDRMHBwWRnZ2MwGBymnz17FqvV6tBHX6FQ0Lp1a1577TVWrVrFm2++yeHDh/m///s/+zIuLi707NmTd955h40bN/Lggw/y7bffkpmZeVvprKxbCRRBQUEAnDlzxmG61WolJSWl3PMK2dnZFBQUOEw7e/YsAHXr1rVP8/b2JikpiVWrVnHx4kV27NhRZV1hK5vmqKgonnvuORYuXMiyZcswGAx8/fXX9vkVKWOheokgIADw2GOPERgYyLRp0zh9+nS5+QUFBRV6yrZTp05YrVYWLFjgMH3+/Pn2+YBDtUGZuLg4AHsAuXoZlUpFdHQ0AHq9/qZpqUplzz9Upoqobdu2qNVqFi5c6FAnvmrVKi5dukRSUpLD8larlcWLF5f7rNPpyj2g1r9/f1JSUnjvvfewWq3069fvVrJ1y2kuKCgoV60TGRmJVqu1l01FyliofqKLqACAp6cns2fPZtSoUQwYMMDeR1yhUHDy5ElWr16Nl5cXL7/88g23k5SURLt27Zg5cybnzp0jNjaWnTt38vPPPzN48GD7SfzTTz9l165ddOrUieDgYPLz81myZAmurq72QDFy5Eh8fX1p3rw5tWrVIjU1lUWLFhETE0NkZORN85SSksLKlSvLTff29qZjx46VOj46nY6oqCjWrFlDvXr18Pb2pm7duiQkJFx3HV9fX0aPHs2MGTN4+umn6dq1K2lpaSxevJgGDRrwyCOPOCzv7+/PggULOHfuHNHR0WzYsIFdu3Yxfvx4eyNrmQ4dOuDr68vatWtp1aqV/Qq+IvLy8vj000/LTa9duzYDBw6sUJp37NjBlClT6NGjh739YM2aNRQWFtK7d2+gYmUsVD8RBAS7+Ph4Vq9ebR876KeffkKWZcLCwhg8eDDDhg276TYkSWLWrFnMnDmTn376iZUrV1KnTh3Gjx/PM888Y1+uS5cunD9/nuXLl5OTk4O3tzdNmzZlzJgx9iqHwYMHs3r1ar755hsKCgoICAhg0KBBPP/88ygUN7+J3bFjxzUbkuPi4iodBADeffdd3nnnHf79739jNBoZMGDADYMAwOjRo/Hx8WHRokX8+9//xtPTkwEDBjB+/HiHZwTA1jj/8ccf89Zbb7F8+XJ8fHx45ZVXePbZZ8ttV61W06dPHxYuXFjpqqDc3FxmzJhRbnpCQoI9CNwszTExMXTo0IGtW7eydOlStFot9evXZ/bs2XTt2hWoWBkL1U+SZfGieUGobrcysNu0adNYvHgxv//+e7leRYJQUaJNQBDuQ0ajkVWrVtGtWzcRAITbIqqDBOE+kp2dze+//8769evJzs7mySefrO4kCfc5EQQE4T5y6tQpXnnlFXx9fZk0aRKNGzeu7iQJ9znRJiAIguDERJuAIAiCExNBQBAEwYndN20CubmFWK2Vr7ny83MnO7vg5gvWMM6Yb2fMMzhnvp0xz1C5fCsUEj4+Nx8Z+L4JAlarfEtBoGxdZ+SM+XbGPINz5tsZ8wxVn+8aXR0kmfWQtb26kyEIgnDPqtFBQJP1M6xvi7LgaHUnRRAE4Z5Uo4OA0a8zKLS4pH1R3UkRBEG4J9XoICBr/CDsMbTnl9iqhgRBEAQHNToIABA1GoWlAO35/1Z3SgRBEO45NT8I1GqFybOprUpIPBwtCILgoOYHAaA4ZBSqwmOoc3+t7qQIgiDcU5wiCJQGDsSq9kGX/mV1J0UQBOGe4hRBAKULJUHD0F5chVR6d19QLgiCcC+7pSCwdu1aRo8eTceOHWnSpAkPPvgg3377rcOLqSdOnEhMTEy5v8q8OakqlQQPR5It6C58Xy37FwRBuBfd0rAR8+fPJygoiNdeew0/Pz927tzJu+++S1paGhMmTLAvFxISwocffuiwbnh4+G0l+FZZ3KIxeTRBe+F/FIeNqZY0CIIg3GtuKQjMnTsXX19f++fExESKiopYvHgxL7/8sv1l1DqdjiZNmlRJQqtCaZ1HcT8xGWXhSSxuUdWdHEEQhGp3S9VBVwaAMg0bNqS0tJS8vLzbTdMdUxo4CBmFeGZAEAThL1XWMLx79268vb3x8/OzT0tNTaVFixbExcXRv39/1qxZU1W7q5DcXPj+eygttX226upg8u2I7sL/xDMDgiAIVNFQ0gcPHmTZsmWMGTMGpVIJ2O4M4uPjqV+/PgaDge+//56XX36ZkpISBg4cWBW7vandu5U88QSEh7vx5pul9O5tpqTOo3gefh5V/i7M3q3vSjoEQRDuVbf9juGsrCweffRRAgMDWbhwIWq1+rrLDh8+nLS0NDZt2nQ7u6yUn3+G8ePhyBHo0AFeHqvnIUsgUuTT0HL2XUuHIAjCvei2goDBYGDYsGGUlpby7bff4uPjc8Plv/32W6ZMmcL27duv2a5wI9nZBbf0MgV/fw/OnzewYIGaTz7RcO6cguV/f5Su8Rs5EH6AqFiPSm/zfuDv70FWlqG6k3FXOWOewTnz7Yx5hsrlW6GQ8PNzv/lyt5qY0tJSnn/+ebKzs/nyyy9vGgCqk0oFTz9tYvfuQpYsKeLP/JG4q7NpdKoB66b+i1VLLlDgfG+qEwRBuLU2AbPZzLhx4zh+/DgLFy4kODj4puvIsszatWsJDg6u9F1AVVEqoXNnC507t+VM6jYK/pzJ481mIPExp5fX57QlFo/QOAJaPQru9aoljYIgCHfTLQWBt956i02bNvHqq69SUlLCvn377PPq169Pfn4+EydOpE+fPoSFhaHX61m6dCm7du3i/fffr6q03xb30ATcQ78kr+gNsv/8Dr10mFqqw0SYVmL99d9sv/AEBWF/J6F9BDdo5hAEQbiv3VIQ+PVX22icH3zwQbl5CxYsICYmBnd3d+bMmUN2djZqtZrY2FjmzJlD586dby/FVUx2DcW3wwR8gZIS+O/6i7infULXsM/RGBfzy+weHDcOJySxB4ntVPzV+UkQBKFGuO3eQXfL7TQM30oDUmn+RXK2f05w6WL8XDPIKfDhx/2PcF77CA07JNI6Ub6nA4IzNpw5Y57BOfPtjHmGO9MwXCXPCdREWq8A6vR8Has8icxzmyk4+B2DWy9Cp/qctLS6/LB6MJmuj9Osc0MSEy33dEAQBEG4HhEEbkZSogjugmdwFwyWQgxpa5At3/NcpxmoFB+x/2hjvv5+IEbfTsS2b0Lb9grRhiAIwn1DBIHKULpB+CO4hD9CnvESUuoP1LH+j9dCp6CQ/oXe4MGfc9pgUDfDL7opkW1ao3Ktnp5QgiAIFSGCwC2SNbWQ6z+HVP85cozZyJnbyDmylXp1dhHi8QEqq4XiTTq2pg8jL3AMzZMi8PKq7lQLgiA4EkGgCsgaPwjpj29IfwAuFBZzYOthNOe/pWPIAnTqL/h9cVtOWSNwDwylTlwcng16gUIcfkEQqpc4C90BWjcXWvZqAbRAXzyJ1F3zCAzcTLi8hUCPDJQZVjKOhLOv5AUC2zxBWKRbdSdZEAQnJYLAHSa5+OPTcSIwEYA/T5k5tW0jDZlOn7p/J+/gW6xb+jjnXZ8kISmeRo2sSFL1plkQBOchgsBdFlFfRUT97kB3jh3fhfHwlwxI+Bqtai4HdsXzw5IelPp0JLxla1q11YmeRoIg3FEiCFQjv5hWENMKg+l9ck59j69xOSODP0Gj/BBTkYojC+LJNDdDE9Sc0MTuePgHVHeSBUGoYUQQuAfIam9UDZ9B1fAZ8i1FWC5s5+LB31C47KWl6zJ8dPOw7FHwZ3oXLun60Lh+BgHqPaiKkikOGUVx6GhEHZIgCLdCBIF7jdIVZXAX6gR3AaDULLPtz6OUHF9GA4+ltPZ5CXOukuOZjdC6BlK/eBJS3n6KGs0ApUs1J14QhPuNCAL3OKVKokFiLCTGgvwPDief4f+2hfJ/G93Ztk3By93e4+1H3uDc9yc5pn6dqDYt8KsjHkgQBKFixABy97GSEti2TUnm7rWMjH0aTxc9VqvE6ew4stVd0dbrQnDTNkhKTfmVy4q9BlUj1eSyvhFnzLcz5hnEAHLCVXQ66NbNAt26U2w6zsl9u8k5vguP4t9pEjQHXe7HGNZ4cCyvG6X+PQlp3QUPdRa680vQnl+KVVeX/KbfI6vFnYMgOCsRBGoIhdqN0JYdCG3ZAQC9WcH6lWtQZ64jwX8tdZTL4E/bslZZid6lA176bXjtHUR+s+XIqpr5rmVBEG5MBIEaKqCOG4mDegI9MZZOZ+POgxSe+IX9R734ZOXjZOkDeK73UmY//jjWTY9Skvg9Lh7iyWVBcDaiTaCGulG+U1MlNmxQsXGjioCS7/n62SGcyYpgX1Yf5MCORLVNJDj85nWJ9xpR1s7DGfMMd6ZNQASBGqqi+S4pgZTf1uGX/SkR7tvRqksxmtX8kdKBDHrhEdOFRokR6Fzu/QZkUdbOwxnzDKJhWLgDdDqI6WKrNso3F5N1ZBf5xzYS7LuOdj6vgBlyf/bmdF5Lit1a4xX/ELVjYmpSpyJBcGoiCAh2ksqFgMYdCWjcEZhCevZZ0vf8SmnebvwVf9LU8z2Uae9wdFdjjhYOxDW0FVGtG+FZy7u6ky4Iwi26pSCwdu1afvzxRw4fPkx+fj4hISE8/vjjPPbYYygUCvtyW7Zs4eOPP+bUqVMEBgby5JNPMmzYsCpLvHBnaf3CiewWDgwF4MDJi1zau5Jg5VIG1v+XbaG9cDYnmhRjFxR1uxPesi06d/HksiDcL24pCMyfP5+goCBee+01/Pz82LlzJ++++y5paWlMmDABgL179zJ69GgeeughJkyYwJ49e3jvvfdQqVQ8/vjjVZoJ4e6oGxVA3ahngWc5X5hNyt795CXvw6NkJy2DvsbVPIeizS7sPt+DfM9+hLfrTmBdz+pOtiAIN3BLDcM5OTn4+jq+O3fq1Kl89913/Pnnn2g0Gp555hny8/NZunSpfZl//vOfbNq0ia1btzrcMVSEaBiunLud78L8Ys7+8Tukr6OhxyoCPc9jNKvZm96OTKkLblGdiWkdh1ZXuXKvDFHWzsMZ8wx3pmH4ln6RVwcAgIYNG1JaWkpeXh5Go5EdO3bQu3dvh2X69u1LVlYWhw8fvpXdCvcwNy8X4rp2Ie6pD5AGHGV/4C/szH8BX/cc+oX9ky7GdqhWx/DnrLFsnL+KQ3vysFiqO9WCIFRZw/Du3bvx9vbGz8+PM2fOYDKZiIyMdFgmKioKgOTkZOLj46tq18I9RlIoCGrckqDGLYF/kZpzgbQ/NqMu3UDb0B/xclmANUti3/zmnC5IQg7sRGTrFoRGiLYEQbjbqiQIHDx4kGXLljFmzBiUSiX5+fkAeHo61geXfS6bLzgHF9/aRPd4DHgMo9VMcspusg9vwcNjE/3rTket/IDSYxr2rG/LeWtHXMIfILpNEzy9rzHwnSAIVeq2g0BWVhYvvvgi8fHxPPvss1WRpmuqSN3W9fj7O+e4OPdqvv0DuxLRqisAstFA+r5fuXhwIwHev9Da+y0UCpnCX13Zf74jlzR98Wvch2YPhOFSgRuFezXPd5oz5tsZ8wxVn+/bCgIGg4Fnn30WnU7HnDlzUP/1QlwvL9uolHq93mH5ss9l8ytDNAxXzv2Ub2299oTUaw+8wYXCHDL2bKckcyvh3v9HW+8xcGkMyZ9FcK4wFrNbAzzCmhDUvDMqF8cLg/spz1XJGfPtjHmGe+yJ4dLSUp5//nmys7NZsmQJPj4+9nmhoaGo1WqSk5Pp0KGDffqpU6cAiIiIuNXdCjWc2s2X8Af6wAN9QP436ZdOcXHfz8jSbmq7HyPU52c0xSZKNmnZc747OboeBMXFU7dRDOCcV4aCcDtuKQiYzWbGjRvH8ePHWbhwIcHBwQ7zNRoNiYmJrF27lqeeeso+ffXq1fj7+xMXF3dbiRachCSh9Y8ipFuUfdKZbBOnd+xGdX4VjbxW0tb7R8gCyy8KzhVFka9sgmvdBDzqtcTi3RKkO9clVRBqglsKAm+99RabNm3i1VdfpaSkhH379tnn1a9fH3d3d8aMGcPQoUN5/fXXefDBB9mzZw9Lly7ljTfeqPQzAoJQxtdPjW+fRCAR5Hc5fOYsZ/YeoSD9CF6WAzQK+o2Q7P9CNmQW1uOsYiheTZ7ALzT4ptsWBGd0Sw+Lde7cmYyMjGvOW7BgAa1btwZsw0b85z//4fTp0wQEBPDUU08xfPjwW0qoaBOoHGfMd61aHmzfXsi+HdmUnN1EC58FdIjZCMDxC41ILu6Exa8DYc2aUrteYDWntuo4Y1k7Y55BDCUtgkAlOGO+r86z1Qqn96dQdGw5vsatNKj1G66aYgCyDIGcK2lCqWcbfBu2w6teU1Dcn11SRVk7j3uqYVgQ7nUKBUQ1DYOmLwEvYTCXcvzgXi4eO4CUd4C6LrtJ0P4LkqHomCtHc5PQu/ckoGl3AsLqVHPqBeHuEEFAcBoKlZa6TROp2zQRALMZNh/IIevwdrR5W0motZbmbj/BCTi6pTHJxV2xBnahXqtWBAZpqzn1gnBniCAgOC2VCuKa+UKzPkAfrJZ/s/PAcQqO/4yf9AvdQmeiUf2Hkr1a9q1uQ4a5A+qgROo1b0LtkPvv9ZuCcC0iCAjCXxRKiYimDaBpA2AcuaUFnN//G8Vnt1HLcyutfN5GoZCxHpE4sTmOC8ZmSL6N8Y9uRK2YBCSVW3VnQRAqTQQBQbgOhdad4FY9oFUPALJKcjl3cA/65N24Wf4gzmct/u4L4ByUpGg5cqkT2bqe+MY+QEjDekhKdTXnQBBuTgQBQagghc6Hui27QMsuAFgtMruOXSTtwEE0uVuI8/6JZj4vw3kwpavILIxAr4yH2l3wi++Cwk00Ngv3HhEEBOEWKZQS9eICqRcXCHRFlt9m//GTXDi8h8ILp9AZT5AQtJ1gww/wO5y81Jh0S3cUdbsS1rwlbh7iTkGofiIICEIVkSQIahBFUIPLw1xkpMP23Ufh3AZC1f9H++CPUZs+RL/Jg4MX2pKtaI8upBWRTSPx9Pe3bUQQ7iIRBAThDgquC8F1GwINgRdIy9Fzbu820G+ijudvtPP7p23B/VBodCOrOIpcTQdc63fFJ6YNklJ0TRXuLBEEBOEu8vD1JKaLrUsqQLo+m/T9e7l05izGnDP4Ko/QJnIu2oxPKEp25WRea/Sa1riHNiG89nl0xYdQFp+hNKAfJcFPiQHyhNsmgoAgVCOtpx+RD3Ql8gHbZ6sVdh0pJvPAr7jkbyRUt522/u+jNFjBAAWlnhis/gRkv4QyZTEljT8G/7bVmgfh/iaCgCDcQxQKaNDIhQaNugHdADiaXsiZfcfYvr8uG34P58ABBY+0XMxHT/wdX0MHjq7pQKE2AfeQxtSKaoTsHnHfjoMk3H1iALkayhnz7Sx5Li2F/fsVHPwzn/rGj4hw30ZsnQPoNKUAmK0qso2RFLi0wSW6H+q6HUFRs3oiOUtZX00MICcIAlottGplpVUrD+Bf1Krlwa4duSTvPU5eynEUBceooztCUuz3eBz/mry9vpwpSETtVQefoNp41A7F7BGHxS0GFKLh2dmJICAI9zlJgoj6KiLqxwG2t/YVFMAve0zoj2+kjnk5gdrDBJbuwj/7EmTb1rPISvIVTZDDHkEOexRZU6v6MiFUGxEEBKEGcneHdh3U0KEH0AOLBQ4fU/DnTjMZJ85izT6Cv+YwvRLW0lyeiOn06xzP60ixaws8wxvjVz8B2SVEPLfgBEQQEAQnoFRCXJyVuDgFEAFEkJfXlz17JrPp4DGCjd/S2P9nmnp/iCrTAplQUOpFprERVrdofANd0bm7IKu8KQ3oi9U1orqzJFQREQQEwUl5e0PnzhboHAW8icXyJjuOl5J+8AjF5w6gKz1CiPtBomr/hKa0CK2mGJXSgvvJ18lRtYV6T2AN6oOs8avurAi3QQQBQRAA291CTKyWmNimQFMAiopg1wElu3cr2L1byblT5+kW9S1PdfiaBuaxWI6/SLI+kRyXnnhHNMEvIgZZW1tUI91HRBAQBOG6XF0hMdFCYqIFMAE+XLgwlp17XuTHg/vxK1lDs4CfaO39BmQAGWAo9eaisREm93jcQxrhFhyP2b2h6Il0j7rlIJCSksK8efPYv38/J0+eJCIigtWrVzssM3HiRJYvX15u3RkzZtCzZ89b3bUgCNWodm2Z3r0t0LsR0Aiz+TW2HbrE+WPHKTp/DF3pMUI8DpIQugD39EJItz27cMnYkBK3JrjWbYo6sBlmj0biobZ7wC0HgZMnT7JlyxYSEhKwWq1c75mzkJAQPvzwQ4dp4eHht7pbQRDuMSoVNGhSiwZNagHtAFsX1U0HJVIOn6X43EFcSw8Q4bOPFvXW4m9ZCClQYnYlo6Q1RR7t8KrXBLc6UVhdQkFSVm+GnMwtB4HOnTvTtWtXwHbFf+jQoWsup9PpaNKkya3uRhCE+5C7OyS2kUlsEwaEAX3JzpbYuE8i9Vg6lou7CVTsoEnQNhJc30WRLEMyGC1aLpnjKPFsh0dEO6TANshqn+rOTo12y0FAoRCjFwqCUHF+fjKdu8jQJQgIAh5Er4d1hwxcOHaMwvOnUBWdoGHAnyTW/xzd0ZlYDitIMTQlR90RXd3WBNYPB/cwwKN6M1OD3PGG4dTUVFq0aEFxcTFRUVGMGjWK3r173+ndCoJwH/D0hJZtPaBtS6AlAOfPSyzdayL3yJ94FG0j2mszLevNRJPzH9hlW89g8keSAlG4BaD1C8NUux8mn46gEH1dKuuOHrGGDRsSHx9P/fr1MRgMfP/997z88suUlJQwcODAO7lrQRDuU3XqyNSpowISgUSs1lfZe6qQ9EPHyU1PxZyXgsaUhq9rJrW9L9Aw6Ae8z80nvzSAs5aH0NVuSK3wcPCIxOoSLrqr3kSVjCJa1iZwde+gaxk+fDhpaWls2rTpdncrCIKTslrhxAnYvRv27ylBm7OWFn6L6Rq7FjddkX25IrM3eVJzVIEt8Y1qiSqwFbgE2wKDLIPVBErn7qF01++devbsyZQpU8jJycHX17fC64mhpCvHGfPtjHkG58y3v78Hfn4GuneH7t0BumK1duXQGTh58CKZp1MwXTqBv3IvTUL/pLH8IapLZgD0pbVQqUCnzEeBCaN3O4rDX8RYq8c9/6Y2MZS0IAjCdSgUEBEJEZEBQADQEqt1CMnJEl/vN5F39jAaw258pYMUFKnJK/LGalXwZMdF1M0bzMWSaM6rB+Ae3grPiBagcY5eSXc1CMiyzNq1awkODq7UXYAgCMKtUCigfn2Z+vVVQAKQgCzDxYsShw4pOHxYyUsbXydEXs4jCbNoFfEhqjQLpMHZ3FgumFtj8WlNrfoN8KtbG1kbUOMan285N8XFxWzZsgWAjIwMCgoKWLduHQDx8fGAra2gT58+hIWFodfrWbp0Kbt27eL999+vgqQLgiBUniRBYKBMYKCFLl0sf019kOLiB9l0uIisY/tQ5e4gULmTxkHL8VHNh7PAWbBYFVwqjSRH2RZl7Xb41E8AtxBQ3bza5V51yw3D6enpdOnS5Zrzpk6dSufOnZk0aRJHjhwhOzsbtVpNbGwsI0eOpHPnzpXen2gTqBxnzLcz5hmcM993K89FhVZSDp3i4umzGDLPY9KfJ9j1AG2jfsXHLc++nMHoi8EaiuxSF5daIaj9ojDW6mrrnVSF7kSbgHjHcA3ljPl2xjyDc+a7OvNsMsHJE3Du6FGKLxzHok9HY0qllksqYbVSCKuVgodLAQCZxTFcUndFF9wUr3pNkd0jb6vxWTQMC4IgVDO1GmLjIDauIdDQPj0nBw4dUvLDIYms5DME8TMtg9bSPmYeLpklkAlGiwaj1Q1Z0oHaE9mnEYpazTF5tcDs2axaBtQTQUAQBKEK+PpChw4WOnQACAGeobj4GbYdsXDhxEnMmftQFZ+gpKAYhVyCr3sOzev9QVjODwCUWlzJktpi9e+IW712WL0SQKG+4+kWQUAQBOEOcXGBps2V0LwB0ACwPaOWmSlx9KiCrw4rSN+Rha5wFw19NtE5biOxin9CNpSYXEg2JKLtMBPPOqF3LI0iCAiCINxFkmR7J0Pt2haSkiyAN9Cd4uLuHD+u4NcjF7Fk7sTX/DtBbkeQ0orxrHPn0iOCgCAIwj3AxQWaNLHSpEktoM9ff3fevf2MtCAIgnBHiSAgCILgxO6b6iCF4taHg72dde9nzphvZ8wzOGe+nTHPUPF8V3S5++ZhMaHqTJw4kV27drFx48Zq2X/Z0+ZTp051eK/EkSNHeOeddzh69ChFRUWsWLGCDRs2MGvWLI4fP37X0zls2DAAFi5ceNf3LQh3y31zJyDcXE5ODl999RWbNm0iIyMDWZYJDQ2lY8eODBs2jMDAwOpO4nVZrVZefvllrFYrEyZMwMXFhaCgoDu+3z179vDbb7/x5JNP4unpecf3V1mFhYW0a9eO4uJilixZQtOmTas7SUINI4JADXH48GGeffZZDAYDffv2ZciQISgUCo4fP87SpUtZv349P//8c3UnE4Dg4GAOHDiASnX563fx4kXOnj3L5MmTeeyxx+zTn3/+eUaNGnXH0rJ3715mzZrFgAEDygWBefPm3bH9VtT69esxm80EBgayatUqEQSEKieCQA1gMBgYM2YMAMuWLSMqKsph/vjx4/niiy+qI2nXJEkSWq3WYVp2djYAHh6OLxBXqVQOweJu0miq/41Tq1atom3btjRs2JD//ve/TJ48GbX6zj9FWlkWiwWLxXJPHDOhckTvoBpgyZIlnD9/ngkTJpQLAGA7sY4fP/6G21i2bBlPPfUU7dq1o1GjRnTv3p3PPvsMq9XqsFxKSgrjxo2jffv2NGrUiPbt2/PCCy9w8eJF+zLbt29nyJAhtGzZkoSEBLp27cpbb71ln5+enk5MTAzLli0DbG0UZW0DkyZNIiYmxl4fP3PmTGJiYsql97fffmP48OE0a9aMpk2bMnDgQJYuXWqf/+eff/LSSy+RlJRkT+frr79OXl6efZmZM2fahzXv0qULMTExxMTEsHPnTsDWJlCWjjLFxcVMmzaNTp062Y/T559/Xu44xcTE8MYbb7Bhwwb69u1Lo0aN6NOnD1u3br1hOVzp4sWL7Nixg969e9OnTx9yc3P59ddfr7nszY4HwMGDB/nb3/5Gq1atSEhIoG/fvnz22Wf2+dfKL9jK58qRf8vK7/PPP2fRokV0796d+Ph49u7dC8BXX33F448/TuvWrYmPj+fBBx8sl5aKpHv69OnExcXZLxCuNHXqVOLj49Hr9Tc5isLNiDuBGmDjxo1otVp69ep1y9tYvHgxkZGRdOzYEY1Gw44dO/jPf/6DwWDglVdeAcBkMjFy5EhKSkp44okn8Pf3Jysri23btnHx4kUCAgI4deoUo0aNIjo6mrFjx+Li4kJqaup1T14AgwcPJiQkhE8++YTBgwfTvHlzatWqdd3lV6xYwcSJE4mMjOSZZ57B29ub48ePs3nzZh555BEA1q1bh8Fg4NFHH8XPz89eLXby5EmWLFmCJEl069aNs2fPsnr1aiZNmoSPj+1NUpGRkdfcryzLjBkzht9++41BgwYRFxfHjh07+Oijj0hPT3cIdAD79u1j06ZNPP7447i5ubFw4UJefPFFNm3aZN/Xjfz000+oVCq6du2Ku7s70dHRrFq1iqSkpEofj+3btzNq1Cj8/PwYOnQoAQEBnDlzho0bN/Lcc8/dNC3XsnLlSoqLi3n00Udxc3PD398fgK+//ppOnTrRq1cvJEnil19+4fXXX8dsNvP4449XON39+/dn7ty5/PTTTwwfPty+nsVi4aeffiIpKemebMe578jCfa9ly5Zyv379Krz8hAkT5KSkJIdpRUVF5ZZ7/fXX5SZNmsilpaWyLMvy0aNH5ejoaHnt2rXX3fbXX38tR0dHy9nZ2dddJi0tTY6OjpZ/+OEH+7QDBw6UmybLsvzJJ5/I0dHR9s8Gg0Fu1qyZPGDAALm4uNhhWavVesP8rFq1So6Ojpb/+OMP+7Qvv/xSjo6OltPS0sotP3ToUHno0KH2zxs2bJCjo6PlmTNnOiw3ceJEOTo6Wj5+/Lh9WnR0tBwXFyefPXvWPq3s+C1cuLD8QbmG/v37yy+88IL985w5c+TGjRvLBoPBPq0ix8NischdunSRO3ToIOfm5l5zmWvlt8zV35ey8mvSpImcmZlZbvlrHfsRI0bIXbt2rVS6ZVmWH3nkEXnQoEEO87dt2yZHR0fLGzZsKLcfofJEdVANUFBQgJub221tw8XFBbBdZeXn55OTk0PLli0pKioiOTkZwL6PX3/9laKiomtup6xO/5dffilXRVIVfv31VwoKChg1ahQ6nc5hniRd7hddlh9ZlikoKCAnJ8feqHr48OFb2veWLVtQKBQOV6UAI0aMAGDz5s0O01u3bk1YWJj9c4MGDXB3dyctLe2m+zp9+jRHjhyhT5/LQwf06dOHkpIS1q9fb59WkeNx+PBh0tLSGD58ON7e3tdc5lZ06dKFgICActPLjr3JZCIvL4+cnBxat25NamoqBoOhwukG6N+/PwcPHrR/B8HWTuLt7U0H23Cdwm0S1UE1gLu7O4WFhbe1jT///JPp06ezf/9+TCaTw7yyH25ISAgjRoxg/vz5rFq1imbNmpGUlES/fv3s1Ru9e/fm+++/5/XXX+fDDz8kMTGRrl270qtXrypp4E1NTQW4ZtvHlc6fP8/777/Pli1byh2bsvxUVkZGBn5+fuWqIOrVq4dCoSAjI8Nhep065Uf98vLyqlA99sqVK9FoNNSrV4+UlBT79Pr167Nq1SoGDBgAVOx4lAWdmx2zygoNvfbIlhs2bODTTz/l2LFjWCwWh3kGgwEPD48Kl2OfPn2YOnUqq1at4qWXXqK4uJj169czYMCAe7KB/H4kgkANEBERwZEjRzAajbfUOyMtLY0RI0YQHh7OpEmTCAoKQqvVcvjwYT788EOHK/qJEycyaNAgNm7cyK+//sq0adOYM2cOixYton79+uh0OhYtWsQff/zBli1b+PXXX3nllVeYP38+3377bbmrvjvBYrHw9NNPk5OTw3PPPUdkZCQuLi5YrVaeeeYZ5Lv0fKRCce0b7ZvtX5ZlVq9ejdFo5MEHHyw3Pzk52d4GczdcfSIvc62y/PPPPxk7dizNmzdnypQpBAQEoFar2bJlC19//XWl7w69vLxISkrixx9/ZNy4cWzYsIGioiIeeuihW8qLUF6NrA46e/YsI0eOpGnTpiQmJvL2229TXFxc3cmqMmvXrmX06NF07NiRJk2akJaWRmlpKWvXrnVYbsuWLQwYMID4+Hi6du163Sdff/nlF4xGI3PnzmXIkCEkJSXRtm1bvLy8rrl8VFQUzz33HAsXLmTZsmUYDAa+/vpr+3yFQkHr1q157bXXWLVqFW+++SaHDx/m//7v/24772VXn4cOHaJDhw7ExMRw8OBBh2U+++wzkpOTMRgMrFq1CqPRSLt27QgJCSm3vcpUhwQHB5OdnV3uTuLs2bNYrVaCg4NvIUfl/fnnn2RkZDB27FhmzJjBjBkzGDJkCHXr1kWlUmG1Whk2bBg5OTn247Fy5crrlnVZvk+ePHnD/V7vLuXcuXMVTvvPP/+MVqvlq6++4pFHHqFjx460bdu2XMAoS/eN0rRhwwYefvhhNm3aRHp6OsOGDeO///0v4eHhJCQk2JdbsWIFPXv2JD4+nj59+rBmzZoKp7c6paSk8MYbb/DQQw8RGxtL3759r7lcRX/H8+bNo3PnzjRu3JiBAweyffv2CqWjxgUBvV7P8OHDKSwsZMaMGUycOJHVq1czefLk6k5alZk/fz4ajYbXXnuNuXPn2q+K3nzzTU6fPg3YHoIaPXo0DRs25JNPPqF27dq89957fPfdd+W2p1QqAccrVKPRyKJFixyWKygowGw2O0yLjIxEq9XaTx65ubnlth8XFwfcejXMldq3b4+7uzvTpk0rlxZZllm3bh0zZswAbHX1bdq0Yfz48WzZsoWvvvqq3PbK6q8rUkXTqVMnrFYrCxYscJg+f/58+/yqsGrVKnQ6Hc888ww9e/bkzJkzLF++nIcffpivvvqK8PBw9Ho9JpOJ9u3b4+LiwmeffUZ0dDRffPEFAwcO5L333uPbb78FbMc/JCSEBQsWOHSRBccyDwkJITk5mZycHPu0Y8eOsWfPngqnXalUIkmSwxV/fn4+P/zwg8NyZeX4+eefU1JSUi5N27dvZ+zYsURERDB79mzc3d05cuQIf/zxh0MvuHXr1jFhwgS6devGF1984VDe97qTJ0+yZcsWwsLCrtsj7crf8ZVle/XveN68eUyfPp0hQ4bw2WefER4ezqhRozh27NhN01HjqoOWLFmCXq9nxYoV+Pr6ArYv5iuvvMLo0aOrvF60OsydO9eeN4DExEQyMzNZvXo1AwYMoG/fvuzfv5/AwEBcXV2ZNGkSXl5ePPzww8yePZt27do5bK99+/ao1Wr+9re/MXjwYIxGIytXrixXnbFjxw6mTJlCjx49qFevHgBr1qyhsLCQ3r17A/Dpp5+ya9cuOnXqRHBwMPn5+SxZsgRXV9cqOUm6u7szcuRIZsyYYe+S+PPPP7NixQoyMzM5ffo03bt358SJE3z//fc8+eST1KtXj7///e/UrVu33PYaNWoEwEcffcSDDz6IWq0mMTERPz+/cssmJSXRrl07Zs6cyblz54iNjWXnzp38/PPPDB48mOjo6NvOn9Fo5Oeff6ZNmza4uLiQnJzMrFmzmDVrlr1r6IABA5g+fToFBQUEBgYSEhLCiRMnOHToEOHh4fj4+BAREcHUqVN57LHHUCgUTJkyheeee47+/fszaNAgAgICSElJYc+ePSxZsgSAhx9+mK+//pqRI0fy8MMPk52dzZIlS6hfv36F25ySkpKYP38+I0aM4KGHHiI/P5///e9/1KpVi6ysLPty7u7u/OMf/2Dy5MkMGjSIvn374u3tzalTp8jMzMTLy4ugoCCmTZuGJEkMHDjQHnyvvKObMWMGPXv25O9//ztg+y0kJyczc+ZMOnbseNvlcSd17tyZrl27ArZq1kOHDpVbZvbs2cTGxvLee+8BtvydP3+e2bNnM3jwYBQKBUajkTlz5jB8+HBGjhwJQKtWrXjwwQeZM2eO/aLoemrcncDWrVtJTEx0OEn26NEDjUZTqQd17mVX5q3MAw88AMCgQYPYu3ev/ce0c+dOBg8ezOLFi+nbty9ZWVnlrgbr1avH7NmzUalUfPDBByxYsICkpCReffVVh+ViYmLo0KEDW7du5f3332fGjBnIsszs2bPp2bMnYOsxEhISwvLly3nrrbf45ptviI2N5bvvvquy6pLff/+dHj162BujFy1axN69e0lISCA5Odn+5W/UqBHz5s3j/PnzGAwGPvzww3Lbio+P5+9//zunT59m0qRJjB8/nlOnTl1zv5IkMWvWLEaMGMG2bduYOnUqR48eZfz48bz55ptVkrfNmzeTn59vP+EvW7aMoKAgh2cDunTpAtiqgIxGI2fOnOGRRx7By8uLzz77jA8++ACz2YzRaLT3hGrXrh0LFy4kMjKS+fPnM3XqVLZt2+bwEFhkZCTTpk3DYDAwdepUNm7cyPvvv2+/k6uI1q1bM23aNPLz83nvvff44YcfrvsQ2sCBA/nss88c0r13716SkpIwm824ubnZq+vKGsIB+zMkaWlpJCcnO/SgAujbty8HDx50uKO5F12vzaiM0Wi0Pyx4pbLfcVnZ7tmzB4PB4HAclEolvXr1YuvWrTdvA6uuvql3SmJiovzBBx+Um967d2958uTJ1ZCiu+P111+XW7VqJZvNZvnkyZNydHS0vGXLFodlsrOz5ejoaHnFihXVlMrbt3z5crl9+/ZyQUGBvGPHDjk6Olo+cOCALMuyvHnzZjk6Olo+deqUwzr79+8v93zA/WLo0KHymDFj5NmzZ8tt27aVY2Nj5UGDBsk7d+6UZVmusWW9fft2OTY2Vl6wYIGcn59vfzagXbt29udWalJ5T5gwQe7Tp4/DtIqW7aJFi+To6Ohyz1usWbNGjo6Ols+fP3/Dfde46iC9Xn/Npwg9PT3Jz8+vhhTdeQcPHmTZsmWMGTMGpVJpz+fVx6Hs8/16HAwGAx988AETJky45nMR18t3WQP3/ZjvrKwsDh06xLFjx/jHP/6Bu7s7X331Fc888wxr1qypsWWdmJjIzJkzeeWVV3jnnXcA253YN998Y+8BVxPL+0oVLVu9Xo9GoynX+F52HPLy8qhdu/Z191PjqoOcTVZWFi+++CLx8fE8++yz1Z2cO+rjjz8mLCyMfv36VXdS7hpZlikqKmLmzJn07t2bDh06MGfOHNzd3e+JUU7vlD179jBhwgRat27No48+ilKpxMvLi1dffbVcQ7Jwe2pcEPD09LxmTw+9Xn/dLo/3K4PBwLPPPotOp2POnDn2h2fK8nn1cSj7fD8eh7Ixf8aNG4der0ev19ufWi4qKqKgoOC6+S67Yrof8+3p6Ym3tzcNGza0T3NxcSEhIYGTJ0/WyLIGeOedd2jdujXHjx9n5cqVdOjQgcWLF3PkyBFWrlwJXP97fj+X95UqWraenp4YjUZKS0sdlis7Dlc/JX61ClUHpaSkMG/ePPbv38/JkyeJiIhg9erVFVmVFStWMHfuXDIyMggNDWXMmDHlGjqqUuvWrct1UzQajZjNZho3bnzH9nu3lZaW8s9//hO1Ws3cuXMdBiQLDQ0lLCzMYWRPsD1dGhwcfM1ROe91mZmZBAYGMmnSJIfpwcHBTJo0icjISKZMmUJwcDDnzp1z6HJ3/vx5goODqV+//t1O9m1r0aJFuSe4wdY5QJKkGlnWYButtWXLlsyaNcthesOGDe0dG6KiompMefv4+JR7+K+iZRsbG0twcDCpqakOvR+zsrJo27btTV8mVaHXS27YsIG3336bhIQEzpw5Y3+i8WbWrVvHuHHjGDVqFO3atWPDhg0sWrSIzz777J7vviUIguAMKhQErFarvTtTWX/WigSBXr16ER0d7dBP9emnn0av1/P9999XKqG5uYVYrZV/3N/Pz53s7IJKr3e/c8Z8O2OewTnz7Yx5hsrlW6GQ8PG5+cCSFaoOull/1msp68P78ssvO0zv27cvkyZNIicn55r93a/HapVvKQiUreuMnDHfzphncM58O2OeoerzfccahsuGfr36ceiyerorh4YVBEEQqscde06gpvfhFSpGlqGwEC5dkggIkHF1vf6yVisUFUFpqURpKahU4O0tc7OBUQsK4MwZBQoFuLlJBAfLqNVQUgIZGRKXLinw87MSECDj4QHFxZCTI6HXS/j7y9SqJXPlOHImE+TnS+j1YDBI9r+CApAk0OnAxUVGlqG4WKKkBEpKJIxG2z6LiyUKCiTKhkoKDJQJDJTx9ZVRKEChALPZto/cXNt2VSrQaGzzjEZbGktLLydKkiAoyEpEhJXQUJniYrhwQUFmpoRSCbm5GiwW0GplPD3B09OWvqIiKCyUyM+//CfLtuPq4yOjVNrKJjtboqgItFpb3lxdbdvw9pZxc4PSUlvejEbpr7Ta8pKTY1s3L09CoQCdTkarBbXalieVypYOs1nCarVN02ptywQFWYmNtRIVZUWrhfz8srQo0OshL0+yH6PcXIniYtvxUSrBzQ1KSrT2Y1OWJqXSlsay9JblubBQwtdXpnZt2/fA21vG3R08PGSCg23H1cfHls/TpxWcOqXg0qXL5VhYKP31Z/t+lHFzg9BQK2FhVmrVkrFYwGKRMJmwf2f0etv3R6+3fUeCgqyEhMgEBMgYDLZjmJ9vW8dikbBYbOVfVGQr/8mTSwkJuXN3PffNw2J+fu63vK6/v8fNF6qBbpRvWbb9SGxfWsjMhEOHbH/p6ZenKxTg7m770+lsJy+TyfZDDAuDyEiIiIC6dW0/RIBjx2DhQli+HFJSbCcisP1YIyMhLg58fC6fKM6fhxMn4NQp2wnwai4u4OFh279OZ1vHarX96fVw4cKVS7ujUIC3N1xr1ACl0pavq7cfEmI7AeTkQBWMc4erqy3NsgxZWbb/1yNJ5eer1bYTcllNrNl8+Them/amaXJzsx0XgNzcy9tzdQV/f1sZ24IYf528brpJAHx9bX9W6+VgYTJd/q6UnbiVStu0khLH/JbNu1bZl/H2tqXTar383QTb1YHVattP2T41msvfFW9v23fN1xcuXYKDB23f9WuVh5eXreyvHu1aqbSVZdnv4MqLktxc+OGHG5cv2Nb38rKV648/OgYSsB2jst+DUmnLq6urLe06nZq/hskCqv58dseCwJV9XP2vyMGt9uHNzi64pbowf38PsrKq4Fd9F5jNtivaI0cUJCcrKCq6fIXp6gru7jIeHrYrSj8/25Vcbq7EhQsSmZm2s0XZlVhxsY6jR02kpdmuwDw9bVc9BoNESopESoqCkpLywyhLku3KuOzLaLs6t13RmM225dVq2xWP1Xp5fYVCpk4dGVdXmZMnlSgUMg88YKFjRyuBgVZ8fWUyMhQcO2b7KyiQ7D9af3+ZiAgrSUkytWpZ0elsP7SyK/L8fNv+y67wyoKQJIGrq0y9ejL16lkJD3fh0KFiUlMV5ORI1Klju8rz87Mdp4sXJXJyJDw9wc/PdiwvXpRITVVw7pyETgc+PrarRC8v23xPTyueHuDuYTv+cPnq/8q7Aq3WdtLWaU3oNGZU2stPb5pMkJVlu5otO8FIEvh4m/DXnsJFrcfk0QKTWcJstm3n6vfvyLLthJOcrCA1VYGbm0zt2rY7jNBQd/LyDKhUtpOwXm87ZrY7Ixk3N7ncyQsuXwRc76V0FostEBQWSvY7BI3GVmZGo+2q1ctLLpfWm5Fl2/qpqbbv+tGjCoxG2/fA39/2/S4rAy8v213L1fu4nd+1xWILcgUFtuOUliZx5oyCs2cVeHvLREfb7k4CA23fAVfSQe2JrLr2+4yNRkhPt90NKZW2E7pGc/n36uZm+76WsVohM9P2ffT0lP/6LuJwN3q1srH3KpNvhUKq0MXzHQsCERERgK3u/8p2gbKhjsvm11T5+ZCdLeHnZ7s9l2Xbre6FCxLp6QpSUmwnn4wMiawsBVlZEpmZkkMVgEol/3VClCkqkq550r4eSYLatZWEhlpRqeDcOQm93nbyiIiw0rmzBT8/GaXSdgvt7S3TsKHty+/qCshWVPrdSFYTJp+2gO3LW3Zlai0tIOOiB2fPKkhJUZCeLpGRYTv5Dh9eQv/+ZgIDZbAUoSo4hrLwGJLZgGQtRbKWIksqUGiQFVrAimQ1IllLsKp8sLjVx+IaiWQuRKXfg0q/F6s2kOLQMaC84tF42QLWElDazmL+/tC4sePw0oqS87ikfYYcpkBWeWFV+2H074Gs8ee6LIVoLq1Hm7kSzaX/QzJasRTWxWqpi6zQIVlLACNmzxYU1fu7/eSg0u/D4+AzKIw5GBp+jDHQ9mSzWg1BQTJBdWzHVHtxFersTagyjyFZbQ/4lNbqSUHsJ1jdrni832oGyRbtJKnsittKixaXL1UVJel4KbUYdV6g0KDRlFVx/HXBJMtozy+BUhWltR92ONNcOcqAoug02ourkZWutuOkDQLv1vj4qPHxcbz40mj4q1pPRjLlozm/FnXudoy1umH07w3SjZsaJckW6KKibN+3m70fRjJmo7mwBazFlAb2t5f31ZSGA7ie+YjisLGYvVped3tKpe2q3MvLdpxiYwGuuD20mtFc+hnNpf9Dc2ITyuKzWJXulNR9muKwsVg1AagMB1HnbEEy69G6xxIVEIclPBIUV51SrSaUhSeQ1V5YNf6g0KJQQJ06touma5JlVIYDaC6uQp23g4KYaVg8Gt34IN2GOxYEQkJCiIiIYM2aNXTr1s0+ffXq1cTHx1eqZ9C9LD/fdpVXUGCr89u3T8mGDUr++EOJxWL7walUtjpnk8nxJO7hIVO3rhV/f5kWDc/QKXodYXVyCPLPx9tXhSnyBWT15TsmWz2jrQ7x0iUFubkSPj62es7atW37KKufjopyR6+v2PC/urTP0WUsxCoHY02ti2Q2oLm0HoXpEgBFIc9RGD0VhUKFZMrH/eg4tBdX4h4xmZD243ngAaXD9iSzHl3GAnS/L0RZeByJ23vXsKxwRbIWoTv/HYbYWZg9mqA7txjXlBlIpjzymy7F7N263HqSMRuvPf1QFtpeXFKWDllSYfTvRUnQUIx+XUHx12sKZQu69Hm4nXobhTkfq9qP0sAByCo3lCUZKErSUFjNyAoNSApczn6M7txiCqKmoCi9iNvpd7Bq/LHogvA6MJSS2o9QFP4SKsMB1Lnb0eRsRFmSjiypMHm3pTjkOczusSiMWbidfhef31tRGDkZZWkm6pxNqPT7QFIgqzyxagIxNJqL2bOpPX+K0gv4/tYCrEXUQsKqCcTo34Oien/H6hKOZMrF48iLaC/anrAtvbDUFmi0juPIKAtP4v1nTxTGLIfpVpU3Rv/elNR+GFOtrg7zFCUZuB99GU32L0iyCVnS4JIxH7NbDEVh47C4lQ2rLSNZTSCXIlmNyEp3rBp/rJpaqAoOo8n6GU32ekDC5N0Gk3cistobZdFplIWnUOl3ozbsv5ym45MoqTsC3MYDl38bkikfr/1DURafRZu5gpK6T1NY/w0UpRdR52xGrd+NVe2DVVsXi2skRv+e5YKVovQCuvSv0WV8jbL0HFaVJyafBygOeQ6VfjcuKbNwSZ2LrPJAYcr+K3cK+/fKogtFH/8lZu/Ev47ROTwPDEOd/4d9HxZdCAUNPrLt/2pWM7rz3+Fy5iNUxcnIKDD5PoCs9im/bBWq0HMCxcXF9pc0LF68mLS0NCZOnAjYhuINDg5m8uTJrFixgiNHjtjXW7t2LS+//DLPPfccbdu25ZdffmHBggW39LDYvVAdVFgIf/yhZPt2JQcPKkk+UUpi3RXkFvqw7kBPZNn2pYqPt9Ctm5l69azk5kq01L1DsOs+1hiWULuOkuBgK6GhVry9QZ2/E5fUT9FmrrziJKUG2YzFrQH5Tf+H1SUMrGZcz/4Hl5RZ5Df7odyVjiZzBRa3hljcYyqdb+9d3VAWncSqDUJRkgaSAqNfV4y1eqDS78U1dTZG3ySKwl7A4+jLKErTMXklosn7DaNvJwyNPgdAlb8Hdc5mdOcWo7AYMHknYvTthNk9Dot7Q6xqX1BobVf/ssV2RW012n6Mf01XGC+hLDqFsvAUslKH2bMZFrdo1Nmb8Dj6EoqSNGS1DwpTDibP5ihMOSiMF8lP+BbvBv0u59lcgPeefqgMB8lvugyTT3skSwGK4hR055egO/8dCmOW/URv9O2A69npqPV7bXmt9wom7zblr+yuoMrfjfvxV1Hn/wlAaUB/DLEfIys9cD3zEa5n3keSbXcmVrUPJu92lAb0xejfq9wPW1l4Eo/Df0Od/weypMTs1RKTd1tAQjLno81cgdkthvwWa+xX824n/olLykyk5h9TmHseZdEptBdXgWyhtPajqHN/RVF6jsL6b4BCg9vJfyErdBRGTaGkzmOgdEFRnIb3nz2QLCXkNV+FVeOPwqxHWXgC7cVVaLLWoDDnUxgxmaKICba7EmO2LWiUnKOk7ghKA/ph9myKNnM5rmenoyo4XKHvHYAsaWwnOkmJOm8nCvPlDiNWtS9m9zhMvp0w+nZEks24pM5Bc/FHJKWO/LjPbXdbsozHwRFoL64kv8n/0GT/gkvqXJAU9uNv0dS2lb/F1se+IPo9isPG2vclmfLx/a0JClM2Rr+uFNd9BmOt7g7lryg6g0vqpyjMBoy+HTH5dsKq9kFVeBxlwSHckqehKEmjKPIfmLzb4HngSSRLIQX13wSFDoXxItrMFagKDlEUOpbCqH+BQoNkykOdswm30++iKjyBybMZJXWfptS/D7LG8b0Wd6I6qEJBID093T6G+dWmTp3KwIEDmThxIsuXL+f48eMO85cvX15u2Iirx/+uiLsZBCwWW/VJcrKC48dtddhHjig5cECB1WIlIvAsrwyYx+MtP8dTa7si0MtRnNGORhn1BIFBLvZtqfJ3472rMxIyBdFTKQ4bY5/neupt3M58gFXlRUndERQHP4lVGwxKHeqcLXjuHwYKNQXR/8YldTZqve0NT0Whz1MYM82+HWXhSXx/b44sqSkKH0dRvVfw93Ol4MAcdGlfojBl227xVV4Uh4yiNHioQ379NtejNOBBCmI/sU2QZYdqA23GIjyOvoQkG/+62pmH2asVunMLcT/2Ksgm+49NllSUBg6gOHQMZq9mlTruN2UuwC353yiLz1IcMgqTzwNIxot473kIZeEppFZzyLXaXjjilvxv1Nmb0Scswhhwjdf2WU1osjegPf9ftFlrkazFWDUBFERPLVdtckOyFe2FH0BSUBo40GE9peEwKv1ezF4tbFfGN6kmQbag0u/D4hZVrv5Zl/oZHsdfJa/ZKkx+nZBMOfhua4TRvxe6zv+zf8cVJedwOTsdl4yvsWpqo2/8lf2CwRZonkedvwurypuSoCFoLq1DYbxEXoufsHhcY1gVqxGPIy+gO/8dhfVeoSh8PN67H0RVcIj8pssx+ba/Kg8yqvxdSOYrWpUVGmSFDiS17URsvIjCmIVFF4bRr+Pl6h3ZirLgCJKlCItrZLkToH1zRWfwO/YcZO+gMGIyVm0AHkdfoqD+mxTXs71cRqXfj/bcIizucRh9O2J1rQeyjGTOx2vfYBQl58hpv89W3Qa4pMzG/cQk8lqsxeTT7pr7vZmyu2Rd5jIAzK6R6BO+xeJ+edwnLCW4n/wHLmlfYHGpB1YjytIM2/JuMRTWfwOjf9/rfv+qLQjcC+50EJBlWLlSxSefaDhxQoHReLkQmkSdZsbw8cQF78NHm4ECCzISRv/eFIc+j8J4EZeU2aj1uzG7x5HX4idktS/IFrx3dUZRcg6Le0PU+X+Q02YXVpcQNBd/wmv/45TUeQJDgw9BVb6wlIUn8Nr7sK1OUu2LoeF0XDIWoig+S267y6/8czn7Ce4nX6c0oD/aiyuw6OqitBjAlI/JqxVmj3gksx51zlasLuHktVpvX1cy5VFrcygFUW9THD7uusdHlbcTbdZaisLHOVzFKguOoUv/CqtrOCbPZpg9GoPyBv1A7wDJlIPXnkGo9bsdphtiZ1MSXP5lJuXWNxtQ5e3E7NUCWe19h1J5mywl+P7WBKsuhLyW/4dr8r9xS55KTpsd+NZrXe47LhmzkZUu5ctCllHn/ooufZ7trkGhJa/ZimtWp11ex4r70XG4ZHyDRVcXRck59AmLMQZU/mKuqvj7qinZ+jS687bXLBp9k8hvtvzmgRbbXbPXgeHkJyzBGNAbZAu+vzXFqq1NXsvbfA+2LKM9/y3q/D8prP/mdb9Pmos/4pLyKVZdEGb3Rpg94jH5JdmD0vWIIHCHgsDevQr++U8tu3apaNjQQufOFiIirNQLt9DSfzFB514BScJYqycWl1CsuroYfTthdb2icVuW0Vxah+f+YZg94slvvgrt+f/hcexl9I2+xOTdGt/fW2P07UhBzHv47OyExTWCvBY/OzZ2XkUyXkJ3bjEldR5H1gbgkjoH9+MTyG6333Z1A3j90QuFOZ/cNr+jztmG2+l3UHuGklt7lEO1kfvRl9Fe+IHsTin2Kw1V/m58diWRn/Bdtf6ob5ulBH8OkpdnK2urJhCLR8XfiHU/0KV9icex8eQ3XojHkRcw+bRD3+S7W67ylEozbY3xLmE3X1i24n78NVzSPkcf+2m5u8m7zd/fg6yLelxSZqG9uIr8hMXI2oCbrwhgNeP7azwWt2jym69Ec3E1XvufIL/xAoyB/e9oum/XfdU76H5QWgpTp2r59FMN/v5W/vOfEh5/3GTrzmU14nHoOXRpP2D0bouh0edYXUKvvzFJwujfC33jb/A8MBTPvY+gKjiC0acDpbUfAUmiMHIy7idfR6XfA5ICfeMFNwwAALKmlsMVutGvGzABTfZ6SlxHIZlyUOfvoCjcNjyHyfcB8nx/xt/fA/NVXxazWwwu5jwk40VkrW1kQWWR7VWKFtdrv+j6vqHUgX9nTMr7ozvwrSgJHobr2el4HnoGyVpK0V9VH7dK1gZS4csqSUFBgw8pjJh03Wqau06SKA5/geLwFyq3nkJFSchI3E69hbLgOC6pc7DoQmzVME6oxr1PoKJOnFDQq5crn36q4cknjezYUcjQoSZ7f163k/9El/kDhZGvk9/ipxsHgCsYA/pgiJuLOm+7rVGowUf2q+7i0NGYPBqjMF5E3+jLil2BXcXiVh+LSz00l2y3rZpL65FkC0b/XhVYtwEAqsJj9mnKotPISFhcwiudFuEuU2gpqvcqkrUUo28SZq8Wdz0J90wAuE3FwU8iSxrcj41Hk7uN4pBRN+wEUJM5Xa5LSmDuXA3Tp2twdZX578IMejdYQKl6IFaCANBe+AHX1DkUhfyNoojXKr2P0jqDkZVuSFajvbcOAAoV+iZLURadwuT7wC3nwVirG7qMhWApQZO1FqsmALNn85uuZ3GzpUVZeByTr613lrLoFFZd6E3vSIR7Q0nQEFSGAxTXfbq6k3JfkzX+lNYehO78d8gKV0qCh1d3kqqN09wJyDKsW6fkgQfceO89LZ07m/l93V4GunfE/cRkfH5vgUvqpygLjuB+5AVMXq0ojH7nlvdnDOhLae2B5aZbdXVuKwCArUpIshajydmEJvsXSmv1qFCDmFVbG6vKE1WB452AxbVmP7hXoyjUFDT8zx19eMhZFIc8B0BJ0ON3vC/+vcxp7gRWrlQxapQLMTEWli4tomvcOjwPPg2SGn381+jOLcL9+ERkSYWs8kbf+BtQ3GTksmpi9H0AWaHD9fS7KMz5FaoKAkCSsLjFoCw8YfssyyiLkm1tFoLgZMxezchvshTTjXpGOQGnCQL//a+akBArGzcWoSs5iNeOR7C4x5HfZAlWlxBKAwegubgC15SZFNafglUXXN1Jvj6lKyaf9miyNyArtBj9kiq8qtktBu1f7QmS6RIKcz4Wt/vnNXyCUJWM/j2qOwnVzimqg/LyYOtWJQ8+aLaN1FdwDAkr+vgvsbrYHi5CkjAGDiCv1cbbrq65G4y1bENxGH07XncslWuxuDVAYbyIZMpBWWQbx8nicp/3DBIE4ZY5RRBYt06FySTRr59t/Fbpr0fHrzcq4P2gtFZP29O5Af0rtV7ZmC7KwhOXg8D93j1UEIRb5hTVQT/+qKZuXStNm9rG5pEstoHVZOWtv6Ogulld65HTbj9WXd1KrWf+q4eQquA4yuKzyJIKyy10VRUEoWao8XcCeXmwebOSvn3N9uE4JPNfdwKVqEa5F1ldQio+xo19nVBkhQvKwuO2nkEuYZdH0RQEwenU+DsB21t8LlcFga06SFbonPPhEEmJ2S0KVeExFKWZWFxFo7AgOLMafyewdCkEB1tp3vzymPaSpfC+rgq6XbZuon/dCYj2AEFwajU6COj18PPPOFQFwV93AtcYtdNZWNxiUJakIVmLRBAQBCdXo4PA5s0qjEYcqoLA1ibgzHcC5r/GEAJEdZAgOLkaHQQaNbIwZQoOVUFQVh10fzcK346yMYRAdA8VBGdXo4NARITMG29cfjl6GclsQFY5cRBwjbANj6HQVrqLqSAINYsTdo+x3Qk49clPof7rDkBRoYHnBEGouZw2CDhzdRBAUfh4qPgrRQRBqKGcMwg4eXUQQGnQ49WdBEEQ7gFOWRdguxPwqO5kCIIgVDvnCwJWI5JscvrqIEEQBHDCICCZbS8id/bqIEEQBKhgEDh79iwjR46kadOmJCYm8vbbb1NcXHzT9YqKivjwww/p2rUrCQkJdO/enVmzZmE0Gm874bfq8giiojpIEAThpg3Der2e4cOHExQUxIwZM8jJyWHq1Knk5OQwffr0G677r3/9iw0bNvDyyy8TFRXFgQMH+OSTT9Dr9UyePLnKMlEZl4OAuBMQBEG4aRBYsmQJer2eFStW4OvrC4BSqeSVV15h9OjRREVFXXM9s9nMunXreOaZZxg2bBgAiYmJnDt3jtWrV1dfELBXBznvsBGCIAhlblodtHXrVhITE+0BAKBHjx5oNBq2bt163fVkWcZiseDh4Vjt4unpiSxXX//0mvBCGUEQhKpy0yBw+vRp6td3HGRMo9EQGhpKcnLydddTq9U89NBDLFy4kP3791NYWMiOHTv43//+x5AhQ24/5bfI/mpJUR0kCIJQsTYBT8/y7+L19PQkPz//huu+9dZbvPnmmzz66KP2aU899RRjx469haRWjbK3illFdZAgCMKdfWL4o48+YsuWLbzzzjuEh4ezb98+Zs+eTa1atXj22WcrtS0/v1s/afv7X1EllWexbS+gNrjU7B5CDvl2Es6YZ3DOfDtjnqHq833TIODp6Ylery83Xa/XExERcd31Tpw4wVdffcWnn35Kly5dAGjZsiVms5lPPvmExx9/HHf3ip/Ys7MLsFor35bg7+9BVpbB/tkl7xLuQFaeDAWG6694n7s6387AGfMMzplvZ8wzVC7fCoVUoYvnm7YJREZGcvr0aYdpRqOR1NTUGwaBU6dOAdCwYUOH6bGxsRiNRjIzM2+auDtBMhcgI4HStVr2LwiCcC+5aRDo0KEDO3bsIDc31z5t/fr1GI1GOnbseN31goODATh8+LDD9EOHDiFJEkFBQbea5ttiH0FUDKEsCIJw8+qgxx57jEWLFjF69GhGjx5NdnY2//73v+ndu7dDr6HJkyezYsUKjhw5AkCjRo1o3Lgxb775JtnZ2YSFhXHgwAE+//xzBg0ahIuLy53L1Q1IlgLRM0gQBOEvFWoT+Oabb3jnnXd44YUX0Gq19OnTh1dffdVhOavVisVisX9WKpXMnTuXGTNm8Pnnn3Pp0iXq1KnD008/zXPPPVf1OakgyezcL5kXBEG4kiRX55NblVBVDcOeex9FUXqevMRtVZm8e44zNpw5Y57BOfPtjHmGamoYrmls1UHiTkAQBAGcMQiYC8Uw0oIgCH9xviBgMYg7AUEQhL84YRAoFEFAEAThL84ZBER1kCAIAuBsQUCWbV1ExXMCgiAIgLMFAWsxElbxaklBEIS/OFUQsL9QRlQHCYIgAM4WBMpeLSmqgwRBEABnCwL2V0uK6iBBEARw1iAgqoMEQRAAZwsC9uog8ZyAIAgCOFsQsFcHiSAgCIIAzhoERHWQIAgC4GxBwF4dJBqGBUEQwNmCgL06SNwJCIIggJMFAYW5AFlSgkJb3UkRBEG4JzhVEMBSYKsKkqTqTokgCMI9wamCgG0YaVEVJAiCUMapgoDCXCB6BgmCIFzBqYKAeL+wIAiCIycLAuKtYoIgCFdyriBgLkBWiSAgCIJQxrmCgEW8VUwQBOFKFQoCZ8+eZeTIkTRt2pTExETefvttiouLK7QDg8HAu+++S4cOHWjUqBGdO3dmxowZt5XoWyWqgwRBEBypbraAXq9n+PDhBAUFMWPGDHJycpg6dSo5OTlMnz79husWFRUxdOhQJEni1VdfJSAggLS0NC5cuFBlGagMUR0kCILg6KZBYMmSJej1elasWIGvry8ASqWSV155hdGjRxMVFXXddT///HMMBgM//vgjbm62apjWrVtXUdIrSbYgWYtEdZAgCMIVblodtHXrVhITE+0BAKBHjx5oNBq2bt16w3W///57Hn74YXsAqE5iGGlBEITybhoETp8+Tf369R2maTQaQkNDSU5Ovu566enpZGVl4ePjw9/+9jfi4+Np0aIFr732Gvn5+bef8kqSzGXDSIsgIAiCUKZCbQKenp7lpnt6et7wZH7p0iUA3n//fTp37sxnn31GRkYGH330EdnZ2cybN69SCfXzu/WTt7+/B+jPA+DhXQsPf+cYStrfSfJ5JWfMMzhnvp0xz1D1+b5pELhVVqsVgLCwMD788EOkvwZt8/DwYNy4cRw4cIDGjRtXeHvZ2QVYrXKl0+Hv70FWlgGV/gI+QH6REmOWodLbud+U5duZOGOewTnz7Yx5hsrlW6GQKnTxfNPqIE9PT/R6fbnper0eLy+v665XNq9Nmzb2AFD2GeDkyZM3TVxVEtVBgiAI5d00CERGRnL69GmHaUajkdTUVCIiIq67XkhICBqN5rrzS0tLK5HM2ydZCgDxQhlBEIQr3TQIdOjQgR07dpCbm2uftn79eoxGIx07drzuehqNhnbt2vH7778jy5ercX777TcAGjVqdDvprrTLQcA56xEFQRCu5aZB4LHHHsPDw4PRo0ezbds2VqxYwdtvv03v3r0deg1NnjyZ2NhYh3XHjh3L6dOnGT9+PNu2beO///0vU6ZMoX379pVqD6gKitJMAKxq77u6X0EQhHvZTRuGPT09+eabb3jnnXd44YUX0Gq19OnTh1dffdVhOavVisVicZjWqFEjvvzySz766CNGjx6Nu7s7vXv35pVXXqnaXFSAOm87FpdwZG3gXd+3IAjCvUqSr6yruYfdVu+gi/n4bYnA6N8LQ9ycO5C6e48z9p5wxjyDc+bbGfMM1dQ7qCZQFh5DYcrB6NO+upMiCIJwT3GKIKDO2QaASQQBQRAEB04RBDS5v2HRhWJ1CavupAiCINxTan4QkGXUub9i8mlX3SkRBEG459T8IKA/isJ0CaPPA9WdEkEQhHtOzQ8CmZsBxJ2AIAjCNdT8IHBxCxZdXawu4dWdEkEQhHtOzQ4CsgwXN9vuAq4YxE4QBEGwqdFBQFl0EkouYhLtAYIgCNdUo4OAKv9PAIyiPUAQBOGaanQQMPl2gsRvsLpcf8hrQRAEZ1ajg4BVFwQRw0V7gCAIwnXU6CAgCIIg3Ngde8dwVVMobv1q/nbWvZ85Y76dMc/gnPl2xjxDxfNd0eXum6GkBUEQhKonqoMEQRCcmAgCgiAITkwEAUEQBCcmgoAgCIITE0FAEATBiYkgIAiC4MREEBAEQXBiIggIgiA4MREEBEEQnFiNDAJnz55l5MiRNG3alMTERN5++22Ki4urO1lVZu3atYwePZqOHTvSpEkTHnzwQb799lusVqvDclu2bGHAgAHEx8fTtWtXFi5cWE0prnqFhYV06NCBmJgYDh486DBvxYoV9OzZk/j4ePr06cOaNWuqKZVVZ8WKFQwcOJDGjRvTunVrRowYQU5Ojn1+TSzrDRs28PDDD9O0aVPatWvHCy+8wNmzZ8std7+Wd0pKCm+88QYPPfQQsbGx9O3b95rLVbRs582bR+fOnWncuDEDBw5k+/btFUpHjQsCer2e4cOHU1hYyIwZM5g4cSKrV69m8uTJ1Z20KjN//nw0Gg2vvfYac+fOpWvXrrz77rt88MEH9mX27t3L6NGjadiwIV988QUDBw7kvffe47vvvqvGlFedWbNmYbFYyk1ft24dEyZMoFu3bnzxxRe0adOG8ePHs2XLlmpIZdWYM2cOU6ZMsefp3XffpX79+phMJqBmlvX27dsZO3YsERERzJo1i9dff53k5GRGjBhBQUGBfbn7ubxPnjzJli1bCAsLIzIy8prLVLRs582bx/Tp0xkyZAifffYZ4eHhjBo1imPHjt08IXIN89lnn8kJCQlydna2fdqqVavk6Oho+cSJE9WYsqpzZd7KvPfee3J8fLxcWloqy7Isjxw5Un744Ycdlnn99dfldu3ayRaL5a6k8045fvy43KRJE3nJkiVydHS0fODAAfu8nj17yi+++KLD8iNGjJAHDRp0t5NZJU6fPi3HxsbKGzduvO4yNbGsJ0+eLCclJclWq9U+bf/+/XJ0dLS8efNm+7T7ubyvLJsJEybIffr0KbdMRcq2tLRUbt68uTxt2jT7MmazWe7Vq1e5Y3MtNe5OYOvWrSQmJuLr62uf1qNHDzQaDVu3bq3GlFWdK/NWpmHDhpSWlpKXl4fRaGTHjh307t3bYZm+ffuSlZXF4cOH71ZS74i33nqLIUOGEB4e7jA9LS2N5ORk+vTp4zC9b9++HDx40KH65H6xbNkygoKCSEpKuub8mlrWZrMZNzc3pCveBeLh4eGwzP1e3grFjU+/FS3bPXv2YDAYHI6DUqmkV69ebN26FfkmY4TWuCBw+vRp6tev7zBNo9EQGhpKcnJyNaXqztu9ezfe3t74+fmRmpqKyWQqd4sZFRUFcF8fhxUrVpCSksLzzz9fbl5Zvq7Od9n34X7M9/79+4mJieHTTz+lXbt2xMXF8fDDD7Nr1y6AGlvWAwYMIDk5mYULF6LX60lPT2fatGlERkbSpk0boGaW95UqWranT58Grn0cioqKyMzMvOF+alwQ0Ov1eHp6lpvu6elJfn5+NaTozjt48CDLli3jySefRKlU2vN59XEo+3y/HgeDwcAHH3zAq6++ipubW7n518u3l5eXw/z7SVZWFr/99hvLli3jH//4B3PmzMHd3Z1nnnmG9PT0GlvWiYmJzJw5k+nTp9OyZUu6dOlCRkaGvT0MamZ5X6miZavX69FoNOh0Ooflyo5DXl7eDfdT44KAs8nKyuLFF18kPj6eZ599trqTc0d9/PHHhIWF0a9fv+pOyl0jyzJFRUXMnDmT3r1706FDB3sgmDdvXnUn747Zs2cPEyZM4OGHH+abb75hxowZSJLE888/T0lJSXUnr0a5b94sVlGenp7o9fpy0/V6PRERNeuF8waDgWeffRadTsecOXNQq9XA5SuAq49D2eey+feTkydPsmTJEr766it7PoqKiuz/CwoKHPLt7+9vX7fsiul+zLenpyfe3t40bNjQPs3FxYWEhAROnjxZI8sa4J133qF169YOvfqaNGlCp06dWLlyJYMHD66R5X2lipatp6cnRqOR0tJStFqtfbmy4+Dt7X3D/dS4O4HIyEh7HVkZo9FIampqjQoCpaWlPP/882RnZ/Pll1/i4+NjnxcaGoparS5XJ3rq1CmA+/I4pKSkYDabGT58OC1btqRly5b87W9/A2D48OEMGTLEnq+r8132fbgf8311+9aVSktLa2RZg63MGjRo4DCtdu3a+Pj4kJqaClAjy/tKFS3bsraAq897p0+fxs3NjcDAwBvup8YFgQ4dOrBjxw5yc3Pt09avX4/RaKRjx47VmLKqYzabGTduHMePH+eLL74gODjYYb5GoyExMZG1a9c6TF+9ejX+/v7ExcXdzeRWiWbNmrFgwQKHv0mTJgEwZcoU3nnnHUJCQoiIiCj3sNDq1auJj4+/Zq+qe11SUhJ5eXkOvXyKiorYt28fcXFxNbKsAYKCgsr1bMrIyCA3N9f+fa+J5X2lipZts2bN8PDwcDgOFouFtWvX8sADDzj0sLqmW+vheu/Kz8+XH3jgAfmxxx6Tt27dKi9fvlxu3bq1/NJLL1V30qrMP//5Tzk6Olr+4osv5L179zr8GQwGWZZlec+ePXJsbKz8j3/8Q96xY4f86aefyg0aNJC//fbbak591dmxY0e55wTWrFkjx8TEyP/5z3/kHTt2yO+++64cExPj0Lf8fmKxWOSHH35Y7ty5s/zjjz/KGzdulIcOHSo3adJEPnv2rCzLNbOsFy5cKEdHR8tvvfWW/Ntvv8k//fST3LdvX7lt27ZyTk6Ofbn7ubyLiorktWvXymvXrpWHDh0qd+zY0f45PT1dluWKl+2XX34px8XFyfPmzZO3b98ujx8/Xm7UqJF89OjRm6ajxgUBWZbl5ORk+emnn5YTEhLkVq1ayVOmTJGLioqqO1lVJikpSY6Ojr7m344dO+zLbd68We7Xr58cFxcnJyUlyd988001prrqXSsIyLIsL1u2TO7evbscFxcn9+rVS169enU1pbBqZGdnyxMmTJBbtGghx8fHy0OHDi2X55pW1larVV6yZIncr18/uUmTJnK7du3k0aNHy6dOnSq37P1a3mlpadf9Hf/www/25Spatl9++aXcqVMnuVGjRvKAAQPk33//vULpkGT5Jk8SCIIgCDVWjWsTEARBECpOBAFBEAQnJoKAIAiCExNBQBAEwYmJICAIguDERBAQBEFwYiIICIIgODERBARBEJyYCAKCIAhO7P8Bgw/6wVoudaMAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":"model_test_data_weight_batch_normalization, accuracy = train_data_augmentation_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.01, 40)\nprint(accuracy)\ny_pred = model_test_data_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T05:04:59.320209Z","iopub.execute_input":"2021-08-31T05:04:59.320793Z","iopub.status.idle":"2021-08-31T09:38:50.10806Z","shell.execute_reply.started":"2021-08-31T05:04:59.320751Z","shell.execute_reply":"2021-08-31T09:38:50.106461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test_data_weight_batch_normalization, accuracy = train_data_augmentation_weight_batch(X_train, X_val, X_test, y_train, y_val, y_test, 0.003, 40)\nprint(accuracy)\ny_pred = model_test_data_weight_batch_normalization.predict(X_test)\ny_pred_val = y_pred.argmax(axis=1)\ny_test_val = y_test.argmax(axis=1)\ntn, fp, fn, tp = confusion_matrix(y_test_val, y_pred_val).ravel()\nprint(\"{} {} {} {}\".format(tn, fp, fn, tp))\nprint(\"TPR/Recall: {}\".format(tp/(tp+fn)))\nprint(\"TNR/Specificity: {}\".format(tn/(tn+fp)))\nprint(\"PPV/Precision: {}\".format(tp/(tp+fp)))\nprint(\"NPV: {}\".format(tn/(tn+fn)))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:30:56.976949Z","iopub.execute_input":"2021-08-31T12:30:56.977758Z","iopub.status.idle":"2021-08-31T16:26:30.574487Z","shell.execute_reply.started":"2021-08-31T12:30:56.977708Z","shell.execute_reply":"2021-08-31T16:26:30.573359Z"},"trusted":true},"execution_count":null,"outputs":[]}]}